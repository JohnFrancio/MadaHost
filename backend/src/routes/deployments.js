// backend/src/routes/deployments.js - CORRIGÃ‰ FINAL
const express = require("express");
const UniversalFrameworkHandler = require("../utils/universalFrameworkHandler");
const router = express.Router();
const supabase = require("../config/supabase");
const { exec } = require("child_process");
const fs = require("fs").promises;
const path = require("path");
const { requireAuth } = require("../middleware/auth");

// Route pour rÃ©cupÃ©rer les dÃ©ploiements d'un projet
router.get("/projects/:projectId", requireAuth, async (req, res) => {
  try {
    console.log(`ğŸ“‹ RÃ©cupÃ©ration dÃ©ploiements projet ${req.params.projectId}`);

    const { page = 1, limit = 20 } = req.query;

    const { data: deployments, error } = await supabase
      .from("deployments")
      .select("*")
      .eq("project_id", req.params.projectId)
      .order("started_at", { ascending: false })
      .limit(parseInt(limit));

    if (error) {
      console.error("âŒ Erreur rÃ©cupÃ©ration dÃ©ploiements:", error);
      return res.status(500).json({
        success: false,
        error: "Erreur lors de la rÃ©cupÃ©ration des dÃ©ploiements",
        details: error.message,
      });
    }

    res.json({
      success: true,
      deployments: deployments || [],
    });
  } catch (error) {
    console.error("âŒ Erreur:", error);
    res.status(500).json({
      success: false,
      error: "Erreur serveur",
    });
  }
});

// Route pour rÃ©cupÃ©rer UN dÃ©ploiement spÃ©cifique (manquant dans ton backend)
router.get("/:deploymentId", requireAuth, async (req, res) => {
  try {
    console.log(`ğŸ” RÃ©cupÃ©ration dÃ©ploiement ${req.params.deploymentId}`);

    const { data: deployment, error } = await supabase
      .from("deployments")
      .select("*, projects!inner(user_id, name)")
      .eq("id", req.params.deploymentId)
      .eq("projects.user_id", req.user.id)
      .single();

    if (error || !deployment) {
      return res.status(404).json({
        success: false,
        error: "DÃ©ploiement non trouvÃ©",
      });
    }

    res.json({
      success: true,
      deployment,
    });
  } catch (error) {
    console.error("âŒ Erreur rÃ©cupÃ©ration dÃ©ploiement:", error);
    res.status(500).json({
      success: false,
      error: "Erreur serveur",
    });
  }
});

// Route pour les statistiques des dÃ©ploiements
router.get("/stats", requireAuth, async (req, res) => {
  try {
    console.log(`ğŸ“Š RÃ©cupÃ©ration stats pour ${req.user.username}`);

    const { data: projects } = await supabase
      .from("projects")
      .select("id")
      .eq("user_id", req.user.id);

    if (!projects || projects.length === 0) {
      return res.json({
        success: true,
        stats: {
          totalDeployments: 0,
          successfulDeployments: 0,
          failedDeployments: 0,
          successRate: 0,
        },
      });
    }

    const projectIds = projects.map((p) => p.id);

    // Compter tous les dÃ©ploiements
    const { count: totalDeployments } = await supabase
      .from("deployments")
      .select("*", { count: "exact" })
      .in("project_id", projectIds);

    // Compter les dÃ©ploiements rÃ©ussis
    const { count: successfulDeployments } = await supabase
      .from("deployments")
      .select("*", { count: "exact" })
      .in("project_id", projectIds)
      .eq("status", "success");

    // Compter les dÃ©ploiements Ã©chouÃ©s
    const { count: failedDeployments } = await supabase
      .from("deployments")
      .select("*", { count: "exact" })
      .in("project_id", projectIds)
      .eq("status", "failed");

    const successRate =
      totalDeployments > 0
        ? Math.round((successfulDeployments / totalDeployments) * 100)
        : 0;

    res.json({
      success: true,
      stats: {
        totalDeployments: totalDeployments || 0,
        successfulDeployments: successfulDeployments || 0,
        failedDeployments: failedDeployments || 0,
        successRate,
      },
    });
  } catch (error) {
    console.error("âŒ Erreur rÃ©cupÃ©ration statistiques:", error);
    res.status(500).json({
      success: false,
      error: "Erreur serveur",
    });
  }
});

// Route pour lancer un dÃ©ploiement
router.post("/deploy/:projectId", requireAuth, async (req, res) => {
  const projectId = req.params.projectId;
  console.log(
    `ğŸš€ Lancement dÃ©ploiement projet ${projectId} par ${req.user.username}`
  );

  try {
    // VÃ©rifier que le projet appartient Ã  l'utilisateur
    const { data: project, error: projectError } = await supabase
      .from("projects")
      .select("*")
      .eq("id", projectId)
      .eq("user_id", req.user.id)
      .single();

    if (projectError || !project) {
      return res.status(404).json({
        success: false,
        error: "Projet non trouvÃ©",
      });
    }

    // VÃ©rifier qu'il n'y a pas dÃ©jÃ  un dÃ©ploiement en cours
    const { data: pendingDeployment } = await supabase
      .from("deployments")
      .select("id")
      .eq("project_id", projectId)
      .in("status", [
        "pending",
        "building",
        "cloning",
        "deploying",
        "configuring",
      ])
      .limit(1);

    if (pendingDeployment && pendingDeployment.length > 0) {
      return res.status(409).json({
        success: false,
        error: "Un dÃ©ploiement est dÃ©jÃ  en cours pour ce projet",
      });
    }

    // CrÃ©er un nouveau dÃ©ploiement
    const { data: deployment, error: deploymentError } = await supabase
      .from("deployments")
      .insert([
        {
          project_id: projectId,
          status: "pending",
          started_at: new Date().toISOString(),
        },
      ])
      .select()
      .single();

    if (deploymentError) {
      console.error("âŒ Erreur crÃ©ation dÃ©ploiement:", deploymentError);
      return res.status(500).json({
        success: false,
        error: "Impossible de crÃ©er le dÃ©ploiement",
        details: deploymentError.message,
      });
    }

    // Lancer le processus de dÃ©ploiement en arriÃ¨re-plan
    deployProject(deployment.id, project);

    res.json({
      success: true,
      deployment: {
        id: deployment.id,
        status: "pending",
        projectId: projectId,
      },
      message: "DÃ©ploiement lancÃ©",
    });
  } catch (error) {
    console.error("âŒ Erreur lancement dÃ©ploiement:", error);
    res.status(500).json({
      success: false,
      error: "Erreur lors du lancement du dÃ©ploiement",
    });
  }
});

// Route pour rÃ©cupÃ©rer les logs d'un dÃ©ploiement
router.get("/:deploymentId/logs", requireAuth, async (req, res) => {
  try {
    const { data: deployment, error } = await supabase
      .from("deployments")
      .select("build_log, deploy_log, status, projects!inner(user_id)")
      .eq("id", req.params.deploymentId)
      .eq("projects.user_id", req.user.id)
      .single();

    if (error || !deployment) {
      return res.status(404).json({
        success: false,
        error: "DÃ©ploiement non trouvÃ©",
      });
    }

    res.json({
      success: true,
      logs: {
        build: deployment.build_log || "",
        deploy: deployment.deploy_log || "",
      },
      status: deployment.status,
    });
  } catch (error) {
    console.error("âŒ Erreur rÃ©cupÃ©ration logs:", error);
    res.status(500).json({
      success: false,
      error: "Erreur serveur",
    });
  }
});

// Route pour annuler un dÃ©ploiement (DELETE au lieu de POST)
router.delete("/:deploymentId", requireAuth, async (req, res) => {
  try {
    console.log(`âŒ Annulation dÃ©ploiement ${req.params.deploymentId}`);

    const { data: deployment, error } = await supabase
      .from("deployments")
      .select("*, projects!inner(user_id)")
      .eq("id", req.params.deploymentId)
      .eq("projects.user_id", req.user.id)
      .single();

    if (error || !deployment) {
      return res.status(404).json({
        success: false,
        error: "DÃ©ploiement non trouvÃ©",
      });
    }

    if (deployment.status === "success" || deployment.status === "failed") {
      return res.status(400).json({
        success: false,
        error: "DÃ©ploiement dÃ©jÃ  terminÃ©",
      });
    }

    // Marquer comme annulÃ©
    await supabase
      .from("deployments")
      .update({
        status: "cancelled",
        completed_at: new Date().toISOString(),
        build_log:
          (deployment.build_log || "") +
          "\nâŒ DÃ©ploiement annulÃ© par l'utilisateur",
      })
      .eq("id", req.params.deploymentId);

    res.json({
      success: true,
      message: "DÃ©ploiement annulÃ©",
    });
  } catch (error) {
    console.error("âŒ Erreur annulation:", error);
    res.status(500).json({
      success: false,
      error: "Erreur serveur",
    });
  }
});

// async function deployProject(deploymentId, project) {
//   try {
//     console.log(
//       `ğŸš€ DÃ©marrage dÃ©ploiement ${deploymentId} pour ${project.name}`
//     );

//     const deploymentDir = path.join(__dirname, "../../temp", deploymentId);
//     const outputDir = path.join(__dirname, "../../public", project.id);
//     let buildLog = "";

//     // Mettre Ã  jour le statut
//     buildLog += `ğŸš€ [${new Date().toISOString()}] DÃ©marrage du dÃ©ploiement...\n`;
//     await supabase
//       .from("deployments")
//       .update({
//         status: "cloning",
//         build_log: buildLog,
//       })
//       .eq("id", deploymentId);

//     // CrÃ©er les dossiers
//     await fs.mkdir(deploymentDir, { recursive: true });
//     await fs.mkdir(outputDir, { recursive: true });

//     // RÃ©cupÃ©rer le token GitHub
//     const { data: user } = await supabase
//       .from("users")
//       .select("access_token")
//       .eq("id", project.user_id)
//       .single();

//     if (!user?.access_token) {
//       throw new Error("Token GitHub manquant pour l'utilisateur");
//     }

//     // Cloner avec le token
//     buildLog += `ğŸ“¥ [${new Date().toISOString()}] Clonage de ${
//       project.github_repo
//     }...\n`;
//     await updateDeploymentLog(deploymentId, buildLog);

//     const cloneCommand = `git clone --depth 1 -b ${
//       project.branch || "main"
//     } https://${user.access_token}@github.com/${
//       project.github_repo
//     }.git ${deploymentDir}`;
//     await execCommand(cloneCommand);
//     buildLog += `âœ… Repository clonÃ© avec succÃ¨s\n`;

//     // RÃ©cupÃ©rer le commit hash
//     try {
//       const commitHash = await execCommand(
//         `cd ${deploymentDir} && git rev-parse HEAD`
//       );
//       await supabase
//         .from("deployments")
//         .update({ commit_hash: commitHash.trim() })
//         .eq("id", deploymentId);
//       buildLog += `ğŸ“‹ Commit: ${commitHash.trim().substring(0, 8)}\n`;
//     } catch (error) {
//       buildLog += `âš ï¸ Impossible de rÃ©cupÃ©rer le commit hash\n`;
//     }

//     // Installation des dÃ©pendances
//     await supabase
//       .from("deployments")
//       .update({ status: "building", build_log: buildLog })
//       .eq("id", deploymentId);

//     const packageJsonPath = path.join(deploymentDir, "package.json");
//     try {
//       await fs.access(packageJsonPath);

//       buildLog += `ğŸ“¦ [${new Date().toISOString()}] Installation des dÃ©pendances...\n`;
//       await updateDeploymentLog(deploymentId, buildLog);

//       const installCmd = project.install_command || "npm install";
//       buildLog += `ğŸ”§ Commande: ${installCmd}\n`;

//       await execCommand(`cd ${deploymentDir} && ${installCmd}`);
//       buildLog += `âœ… DÃ©pendances installÃ©es\n`;
//     } catch (error) {
//       buildLog += `âš ï¸ Pas de package.json ou erreur installation\n`;
//     }

//     // Build du projet
//     // if (project.build_command) {
//     //   buildLog += `ğŸ—ï¸ [${new Date().toISOString()}] Build du projet...\n`;
//     //   buildLog += `ğŸ”§ Commande: ${project.build_command}\n`;
//     //   await updateDeploymentLog(deploymentId, buildLog);

//     //   try {
//     //     await execCommand(`cd ${deploymentDir} && ${project.build_command}`);
//     //     buildLog += `âœ… Build rÃ©ussi\n`;
//     //   } catch (buildError) {
//     //     buildLog += `âš ï¸ Build Ã©chouÃ©, copie des fichiers source\n`;
//     //   }
//     // }
//     if (project.build_command) {
//       buildLog += `ğŸ—ï¸ [${new Date().toISOString()}] Build du projet...\n`;
//       buildLog += `ğŸ”§ Commande: ${project.build_command}\n`;
//       await updateDeploymentLog(deploymentId, buildLog);

//       try {
//         // Pour Vite, assurer que les assets ont les bons chemins relatifs
//         const viteConfigPath = path.join(deploymentDir, "vite.config.js");
//         const packageJsonPath = path.join(deploymentDir, "package.json");

//         // VÃ©rifier si c'est un projet Vite
//         let isViteProject = false;
//         try {
//           const packageJson = JSON.parse(
//             await fs.readFile(packageJsonPath, "utf8")
//           );
//           isViteProject =
//             packageJson.devDependencies?.vite || packageJson.dependencies?.vite;
//           buildLog += `ğŸ” Projet Vite dÃ©tectÃ©: ${!!isViteProject}\n`;
//         } catch (e) {
//           buildLog += `âš ï¸ Impossible de lire package.json\n`;
//         }

//         // Si c'est Vite, crÃ©er/modifier la config pour les chemins relatifs
//         if (isViteProject) {
//           const viteConfig = `import { defineConfig } from 'vite'
//             import react from '@vitejs/plugin-react'

//             export default defineConfig({
//               plugins: [react()],
//               base: './',  // CRUCIAL: chemins relatifs pour les assets
//               build: {
//                 outDir: 'dist',
//                 assetsDir: 'assets'
//               }
//             })`;
//           await fs.writeFile(viteConfigPath, viteConfig);
//           buildLog += `âš™ï¸ Configuration Vite mise Ã  jour pour chemins relatifs\n`;
//         }

//         await execCommand(
//           `cd ${deploymentDir} && NODE_ENV=production ${project.build_command}`
//         );
//         buildLog += `âœ… Build rÃ©ussi\n`;
//       } catch (buildError) {
//         buildLog += `âš ï¸ Build Ã©chouÃ©: ${buildError.message}\n`;
//         buildLog += `ğŸ“ Tentative de dÃ©ploiement des fichiers source...\n`;
//       }
//     }

//     // AprÃ¨s le build, vÃ©rifier la taille du CSS
//     const cssFiles = await fs
//       .readdir(path.join(deploymentDir, "dist/assets"))
//       .then((files) => files.filter((f) => f.endsWith(".css")));

//     for (const cssFile of cssFiles) {
//       const cssPath = path.join(deploymentDir, "dist/assets", cssFile);
//       const cssContent = await fs.readFile(cssPath, "utf8");

//       buildLog += `ğŸ“ ${cssFile}: ${cssContent.length} caractÃ¨res\n`;

//       // Si le CSS ne contient que les directives @tailwind, c'est un problÃ¨me
//       if (cssContent.includes("@tailwind") && cssContent.length < 10000) {
//         buildLog += `âŒ Tailwind pas compilÃ© dans ${cssFile}\n`;

//         // Solution d'urgence : build Tailwind manuellement
//         try {
//           await execCommand(
//             `cd ${deploymentDir} && npx tailwindcss -i src/index.css -o dist/assets/${cssFile} --minify`
//           );
//           buildLog += `ğŸ”§ Tailwind recompilÃ© manuellement\n`;
//         } catch (e) {
//           buildLog += `âš ï¸ Ã‰chec recompilation: ${e.message}\n`;
//         }
//       }
//     }

//     // Copie des fichiers - CORRECTION ICI
//     await supabase
//       .from("deployments")
//       .update({ status: "deploying", build_log: buildLog })
//       .eq("id", deploymentId);

//     buildLog += `ğŸ“ [${new Date().toISOString()}] Copie des fichiers...\n`;
//     await updateDeploymentLog(deploymentId, buildLog);

//     const outputDirectory = project.output_dir || "dist";
//     const sourceDir = path.join(deploymentDir, outputDirectory);

//     // Debug: vÃ©rifier l'existence du dossier
//     buildLog += `ğŸ” VÃ©rification dossier source: ${sourceDir}\n`;

//     try {
//       // Lister le contenu du dossier de dÃ©ploiement pour debug
//       const tempContent = await execCommand(`ls -la "${deploymentDir}"`);
//       buildLog += `ğŸ“‹ Contenu dossier temp:\n${tempContent}`;

//       // VÃ©rifier si le dossier de build existe
//       await fs.access(sourceDir);
//       buildLog += `âœ… Dossier ${outputDirectory} trouvÃ©\n`;

//       // Lister le contenu du dossier dist pour debug
//       const distContent = await execCommand(`ls -la "${sourceDir}"`);
//       buildLog += `ğŸ“ Contenu du dossier ${outputDirectory}:\n${distContent}`;

//       // CORRECTION: Nettoyer et recrÃ©er le dossier de destination
//       await execCommand(`rm -rf "${outputDir}"/*`);
//       await execCommand(`mkdir -p "${outputDir}"`);

//       // Copier TOUT le contenu en prÃ©servant la structure
//       await execCommand(`cp -r "${sourceDir}/"* "${outputDir}/"`);
//       buildLog += `âœ… Tous les fichiers copiÃ©s depuis ${outputDirectory} avec structure prÃ©servÃ©e\n`;

//       // VÃ©rifier la structure finale copiÃ©e
//       const finalStructure = await execCommand(`find "${outputDir}" -type f`);
//       buildLog += `ğŸ“Š Structure finale:\n${finalStructure}`;

//       // VÃ©rifier spÃ©cifiquement le dossier assets
//       try {
//         const assetsContent = await execCommand(
//           `ls -la "${outputDir}/assets/"`
//         );
//         buildLog += `ğŸ“ Contenu du dossier assets:\n${assetsContent}`;
//       } catch (assetsError) {
//         buildLog += `âš ï¸ Pas de dossier assets dans la destination finale\n`;
//       }
//     } catch (error) {
//       buildLog += `âš ï¸ Dossier ${outputDirectory} introuvable, tentative copie alternative...\n`;

//       try {
//         // Alternative: Copier rÃ©cursivement tous les fichiers statiques
//         await execCommand(
//           `rsync -av --include="*/" --include="*.html" --include="*.css" --include="*.js" --include="*.png" --include="*.jpg" --include="*.svg" --include="*.ico" --include="*.gif" --include="*.woff*" --include="*.ttf" --exclude="*" "${deploymentDir}/" "${outputDir}/"`
//         );
//         buildLog += `âœ… Fichiers statiques copiÃ©s avec rsync\n`;
//       } catch (rsyncError) {
//         // DerniÃ¨re tentative: copie basique
//         await execCommand(
//           `find "${deploymentDir}" -maxdepth 3 \\( -name "*.html" -o -name "*.css" -o -name "*.js" -o -name "*.png" -o -name "*.jpg" -o -name "*.gif" -o -name "*.svg" -o -name "*.ico" -o -name "*.woff*" -o -name "*.ttf" \\) -exec cp {} "${outputDir}/" \\; 2>/dev/null || true`
//         );
//         buildLog += `âœ… Fichiers statiques copiÃ©s (mÃ©thode basique)\n`;
//       }
//     }
//     const indexPath = path.join(outputDir, "index.html");
//     try {
//       let indexContent = await fs.readFile(indexPath, "utf8");

//       buildLog += `ğŸ”§ [${new Date().toISOString()}] Correction des chemins dans index.html...\n`;

//       // Remplacer les chemins absolus par des chemins relatifs
//       indexContent = indexContent
//         .replace(/href="\/assets\//g, 'href="./assets/')
//         .replace(/src="\/assets\//g, 'src="./assets/')
//         .replace(/href="\//g, 'href="./')
//         .replace(/src="\//g, 'src="./');

//       await fs.writeFile(indexPath, indexContent);
//       buildLog += `âœ… Chemins corrigÃ©s dans index.html\n`;

//       // VÃ©rifier que les fichiers CSS/JS rÃ©fÃ©rencÃ©s existent
//       const cssMatches =
//         indexContent.match(/href="\.\/assets\/[^"]+\.css"/g) || [];
//       const jsMatches =
//         indexContent.match(/src="\.\/assets\/[^"]+\.js"/g) || [];

//       buildLog += `ğŸ¨ Fichiers CSS rÃ©fÃ©rencÃ©s: ${cssMatches.length}\n`;
//       buildLog += `ğŸ“œ Fichiers JS rÃ©fÃ©rencÃ©s: ${jsMatches.length}\n`;

//       // VÃ©rifier l'existence des fichiers CSS
//       for (const cssMatch of cssMatches) {
//         const cssFile = cssMatch.match(/href="(.+)"/)[1].replace("./", "");
//         const cssPath = path.join(outputDir, cssFile);
//         try {
//           await fs.access(cssPath);
//           buildLog += `âœ… CSS trouvÃ©: ${cssFile}\n`;
//         } catch (e) {
//           buildLog += `âŒ CSS manquant: ${cssFile}\n`;
//         }
//       }
//     } catch (indexFixError) {
//       buildLog += `âš ï¸ Impossible de corriger index.html: ${indexFixError.message}\n`;
//     }

//     // Lister la structure finale pour debug
//     try {
//       const structure = await execCommand(
//         `find "${outputDir}" -type f | head -20`
//       );
//       buildLog += `ğŸ“Š Structure finale (20 premiers fichiers):\n${structure}`;
//     } catch (listError) {
//       buildLog += `âš ï¸ Impossible de lister la structure finale\n`;
//     }
//     // Lister les fichiers copiÃ©s pour debug
//     try {
//       const fileList = await execCommand(`ls -la "${outputDir}"`);
//       buildLog += `ğŸ“‹ Contenu du dossier de dÃ©ploiement:\n${fileList}`;
//     } catch (listError) {
//       buildLog += `âš ï¸ Impossible de lister les fichiers copiÃ©s\n`;
//     }

//     // Configuration domaine
//     await supabase
//       .from("deployments")
//       .update({ status: "configuring", build_log: buildLog })
//       .eq("id", deploymentId);

//     const domain = `${project.name
//       .toLowerCase()
//       .replace(/[^a-z0-9]/g, "-")}.madahost.me`;

//     await supabase
//       .from("projects")
//       .update({
//         domain,
//         status: "active",
//         last_deployed: new Date().toISOString(),
//       })
//       .eq("id", project.id);

//     buildLog += `âœ… [${new Date().toISOString()}] DÃ©ploiement rÃ©ussi!\n`;
//     buildLog += `ğŸŒ Site disponible: http://localhost:3002/project/${project.id}/\n`;

//     // SuccÃ¨s final
//     await supabase
//       .from("deployments")
//       .update({
//         status: "success",
//         build_log: buildLog,
//         completed_at: new Date().toISOString(),
//       })
//       .eq("id", deploymentId);

//     // Nettoyer aprÃ¨s 10 secondes
//     setTimeout(async () => {
//       try {
//         await execCommand(`rm -rf ${deploymentDir}`);
//         console.log(`ğŸ§¹ Nettoyage terminÃ©: ${deploymentDir}`);
//       } catch (error) {
//         console.error("âŒ Erreur nettoyage:", error);
//       }
//     }, 10000);
//   } catch (error) {
//     console.error(`âŒ Erreur dÃ©ploiement ${deploymentId}:`, error);

//     await supabase
//       .from("deployments")
//       .update({
//         status: "failed",
//         build_log: `âŒ [${new Date().toISOString()}] Erreur: ${
//           error.message
//         }\n`,
//         completed_at: new Date().toISOString(),
//       })
//       .eq("id", deploymentId);

//     // Nettoyer en cas d'erreur
//     try {
//       await execCommand(
//         `rm -rf ${path.join(__dirname, "../../temp", deploymentId)}`
//       );
//     } catch (cleanupError) {
//       console.error("âŒ Erreur nettoyage:", cleanupError);
//     }
//   }
// }

// Fonction deployProject complÃ¨te avec toutes nos corrections prÃ©cÃ©dentes + nouvelle fonctionnalitÃ©
async function deployProject(deploymentId, project) {
  try {
    console.log(
      `ğŸš€ DÃ©marrage dÃ©ploiement ${deploymentId} pour ${project.name}`
    );

    const deploymentDir = path.join(__dirname, "../../temp", deploymentId);
    const outputDir = path.join(__dirname, "../../public", project.id);
    let buildLog = "";

    // Mettre Ã  jour le statut
    buildLog += `ğŸš€ [${new Date().toISOString()}] DÃ©marrage du dÃ©ploiement...\n`;
    await supabase
      .from("deployments")
      .update({
        status: "cloning",
        build_log: buildLog,
      })
      .eq("id", deploymentId);

    // CrÃ©er les dossiers
    await fs.mkdir(deploymentDir, { recursive: true });
    await fs.mkdir(outputDir, { recursive: true });

    // RÃ©cupÃ©rer le token GitHub
    const { data: user } = await supabase
      .from("users")
      .select("access_token")
      .eq("id", project.user_id)
      .single();

    if (!user?.access_token) {
      throw new Error("Token GitHub manquant pour l'utilisateur");
    }

    // Cloner avec le token
    buildLog += `ğŸ“¥ [${new Date().toISOString()}] Clonage de ${
      project.github_repo
    }...\n`;
    await updateDeploymentLog(deploymentId, buildLog);

    const cloneCommand = `git clone --depth 1 -b ${
      project.branch || "main"
    } https://${user.access_token}@github.com/${
      project.github_repo
    }.git ${deploymentDir}`;
    await execCommand(cloneCommand);
    buildLog += `âœ… Repository clonÃ© avec succÃ¨s\n`;

    // RÃ©cupÃ©rer le commit hash
    try {
      const commitHash = await execCommand(
        `cd ${deploymentDir} && git rev-parse HEAD`
      );
      await supabase
        .from("deployments")
        .update({ commit_hash: commitHash.trim() })
        .eq("id", deploymentId);
      buildLog += `ğŸ“‹ Commit: ${commitHash.trim().substring(0, 8)}\n`;
    } catch (error) {
      buildLog += `âš ï¸ Impossible de rÃ©cupÃ©rer le commit hash\n`;
    }

    // ==================== DÃ‰TECTION AUTOMATIQUE DES FRAMEWORKS ====================

    buildLog += `ğŸ” [${new Date().toISOString()}] DÃ©tection des frameworks...\n`;
    await updateDeploymentLog(deploymentId, buildLog);

    const frameworkHandler = new UniversalFrameworkHandler();
    const { frameworks, log: detectionLog } =
      await frameworkHandler.detectFrameworks(deploymentDir);
    buildLog += detectionLog;

    if (frameworks.length === 0) {
      buildLog += `â„¹ï¸ Aucun framework CSS/JS spÃ©cial dÃ©tectÃ©, build standard\n`;
    } else {
      buildLog += `ğŸ¯ Frameworks dÃ©tectÃ©s: ${frameworks.join(", ")}\n`;

      // Configuration automatique des frameworks
      const { buildLog: setupLog, missingDeps } =
        await frameworkHandler.setupFrameworks(
          deploymentDir,
          frameworks,
          buildLog
        );
      buildLog = setupLog;

      if (missingDeps.length > 0) {
        buildLog += `ğŸ“¦ DÃ©pendances ajoutÃ©es: ${missingDeps.join(", ")}\n`;
      }
    }

    // ==================== FIN DÃ‰TECTION FRAMEWORKS ====================

    // Installation des dÃ©pendances (maintenant avec les nouvelles dÃ©pendances)
    await supabase
      .from("deployments")
      .update({ status: "building", build_log: buildLog })
      .eq("id", deploymentId);

    const packageJsonPath = path.join(deploymentDir, "package.json");
    try {
      await fs.access(packageJsonPath);

      buildLog += `ğŸ“¦ [${new Date().toISOString()}] Installation des dÃ©pendances...\n`;
      await updateDeploymentLog(deploymentId, buildLog);

      const installCmd = project.install_command || "npm install";
      buildLog += `ğŸ”§ Commande: ${installCmd}\n`;

      await execCommand(`cd ${deploymentDir} && ${installCmd}`);
      buildLog += `âœ… DÃ©pendances installÃ©es\n`;
    } catch (error) {
      buildLog += `âš ï¸ Pas de package.json ou erreur installation\n`;
    }

    // Build du projet avec configuration universelle
    if (project.build_command) {
      buildLog += `ğŸ—ï¸ [${new Date().toISOString()}] Build du projet...\n`;
      buildLog += `ğŸ”§ Commande: ${project.build_command}\n`;
      await updateDeploymentLog(deploymentId, buildLog);

      try {
        // VÃ©rifier si c'est un projet Vite et corriger la configuration de base
        const packageJsonPath = path.join(deploymentDir, "package.json");
        let isViteProject = false;

        try {
          const packageJson = JSON.parse(
            await fs.readFile(packageJsonPath, "utf8")
          );
          isViteProject =
            packageJson.devDependencies?.vite || packageJson.dependencies?.vite;
          buildLog += `ğŸ” Projet Vite dÃ©tectÃ©: ${!!isViteProject}\n`;
        } catch (e) {
          buildLog += `âš ï¸ Impossible de lire package.json\n`;
        }

        // Variables d'environnement universelles
        const universalEnv = {
          NODE_ENV: "production",
          TAILWIND_MODE: frameworks.includes("tailwind") ? "build" : undefined,
          VITE_NODE_ENV: "production",
          CI: "true",
        };

        // Build avec configuration optimisÃ©e
        await execCommand(
          `cd ${deploymentDir} && ${project.build_command}`,
          universalEnv
        );
        buildLog += `âœ… Build rÃ©ussi\n`;

        // VÃ©rification post-build universelle
        buildLog += `ğŸ” VÃ©rification du build...\n`;
        buildLog = await verifyUniversalBuild(
          deploymentDir,
          frameworks,
          buildLog
        );
      } catch (buildError) {
        buildLog += `âš ï¸ Build Ã©chouÃ©: ${buildError.message}\n`;

        // Tentative de build alternatif pour Tailwind
        if (frameworks.includes("tailwind")) {
          buildLog += `ğŸ”„ Tentative de build Tailwind manuel...\n`;
          try {
            // Build Tailwind en premier
            await execCommand(
              `cd ${deploymentDir} && npx tailwindcss -i src/index.css -o dist/assets/index.css --minify`
            );
            buildLog += `âœ… Tailwind compilÃ© manuellement\n`;

            // Puis relancer le build principal
            await execCommand(
              `cd ${deploymentDir} && ${project.build_command}`,
              { NODE_ENV: "production" }
            );
            buildLog += `âœ… Build principal rÃ©ussi aprÃ¨s Tailwind\n`;
          } catch (e) {
            buildLog += `âŒ Ã‰chec build alternatif: ${e.message}\n`;
            // Continue malgrÃ© l'erreur
          }
        }
      }
    }

    // Copie des fichiers - logique existante amÃ©liorÃ©e
    await supabase
      .from("deployments")
      .update({ status: "deploying", build_log: buildLog })
      .eq("id", deploymentId);

    buildLog += `ğŸ“ [${new Date().toISOString()}] Copie des fichiers...\n`;
    await updateDeploymentLog(deploymentId, buildLog);

    const outputDirectory = project.output_dir || "dist";
    const sourceDir = path.join(deploymentDir, outputDirectory);

    buildLog += `ğŸ” VÃ©rification dossier source: ${sourceDir}\n`;

    try {
      await fs.access(sourceDir);
      buildLog += `âœ… Dossier ${outputDirectory} trouvÃ©\n`;

      // Debug: lister le contenu du dossier source
      const sourceContent = await execCommand(`ls -la "${sourceDir}"`);
      buildLog += `ğŸ“ Contenu source:\n${sourceContent}`;

      // Nettoyer et recrÃ©er le dossier de destination
      await execCommand(`rm -rf "${outputDir}"/*`);
      await execCommand(`mkdir -p "${outputDir}"`);

      // Copier avec preservation des liens symboliques et permissions
      await execCommand(
        `cp -r "${sourceDir}/"* "${outputDir}/" 2>/dev/null || true`
      );
      buildLog += `âœ… Fichiers copiÃ©s depuis ${outputDirectory}\n`;

      // VÃ©rifier que les assets ont Ã©tÃ© copiÃ©s
      const assetsDir = path.join(outputDir, "assets");
      if (
        await fs
          .access(assetsDir)
          .then(() => true)
          .catch(() => false)
      ) {
        const assetsContent = await execCommand(`ls -la "${assetsDir}"`);
        buildLog += `ğŸ“ Assets copiÃ©s:\n${assetsContent}`;
      }
    } catch (error) {
      buildLog += `âš ï¸ Dossier ${outputDirectory} introuvable, copie alternative...\n`;

      try {
        // Alternative avec rsync
        await execCommand(
          `rsync -av --include="*/" --include="*.html" --include="*.css" --include="*.js" --include="*.png" --include="*.jpg" --include="*.svg" --include="*.ico" --include="*.gif" --include="*.woff*" --include="*.ttf" --exclude="*" "${deploymentDir}/" "${outputDir}/"`
        );
        buildLog += `âœ… Fichiers statiques copiÃ©s avec rsync\n`;
      } catch (rsyncError) {
        // DerniÃ¨re tentative avec find
        await execCommand(
          `find "${deploymentDir}" -maxdepth 3 \\( -name "*.html" -o -name "*.css" -o -name "*.js" -o -name "*.png" -o -name "*.jpg" -o -name "*.gif" -o -name "*.svg" -o -name "*.ico" -o -name "*.woff*" -o -name "*.ttf" \\) -exec cp {} "${outputDir}/" \\; 2>/dev/null || true`
        );
        buildLog += `âœ… Fichiers statiques copiÃ©s (mÃ©thode basique)\n`;
      }
    }

    // Correction des chemins dans index.html
    const indexPath = path.join(outputDir, "index.html");
    try {
      let indexContent = await fs.readFile(indexPath, "utf8");

      buildLog += `ğŸ”§ [${new Date().toISOString()}] Correction des chemins dans index.html...\n`;

      // Remplacer les chemins absolus par des chemins relatifs
      const originalContent = indexContent;
      indexContent = indexContent
        .replace(/href="\/assets\//g, 'href="./assets/')
        .replace(/src="\/assets\//g, 'src="./assets/')
        .replace(/href="\//g, 'href="./')
        .replace(/src="\//g, 'src="./');

      if (originalContent !== indexContent) {
        await fs.writeFile(indexPath, indexContent);
        buildLog += `âœ… Chemins corrigÃ©s dans index.html\n`;
      } else {
        buildLog += `â„¹ï¸ Chemins dÃ©jÃ  corrects dans index.html\n`;
      }

      // VÃ©rifier les rÃ©fÃ©rences CSS/JS
      const cssMatches = indexContent.match(/href="[^"]*\.css"/g) || [];
      const jsMatches = indexContent.match(/src="[^"]*\.js"/g) || [];

      buildLog += `ğŸ¨ RÃ©fÃ©rences CSS: ${cssMatches.length}, JS: ${jsMatches.length}\n`;
    } catch (indexFixError) {
      buildLog += `âš ï¸ Impossible de corriger index.html: ${indexFixError.message}\n`;
    }

    // Configuration domaine
    await supabase
      .from("deployments")
      .update({ status: "configuring", build_log: buildLog })
      .eq("id", deploymentId);

    const domain = `${project.name
      .toLowerCase()
      .replace(/[^a-z0-9]/g, "-")}.madahost.me`;

    await supabase
      .from("projects")
      .update({
        domain,
        status: "active",
        last_deployed: new Date().toISOString(),
      })
      .eq("id", project.id);

    // VÃ©rification finale
    try {
      const finalStructure = await execCommand(
        `find "${outputDir}" -type f | head -10`
      );
      buildLog += `ğŸ“Š Structure finale (10 premiers fichiers):\n${finalStructure}`;
    } catch (e) {
      buildLog += `âš ï¸ Impossible de lister la structure finale\n`;
    }

    buildLog += `âœ… [${new Date().toISOString()}] DÃ©ploiement rÃ©ussi!\n`;
    buildLog += `ğŸŒ Site disponible: http://localhost:3002/project/${project.id}/\n`;

    // SuccÃ¨s final
    await supabase
      .from("deployments")
      .update({
        status: "success",
        build_log: buildLog,
        completed_at: new Date().toISOString(),
      })
      .eq("id", deploymentId);

    // Nettoyer aprÃ¨s 10 secondes
    setTimeout(async () => {
      try {
        await execCommand(`rm -rf ${deploymentDir}`);
        console.log(`ğŸ§¹ Nettoyage terminÃ©: ${deploymentDir}`);
      } catch (error) {
        console.error("âŒ Erreur nettoyage:", error);
      }
    }, 10000);
  } catch (error) {
    console.error(`âŒ Erreur dÃ©ploiement ${deploymentId}:`, error);

    let finalLog = buildLog || "";
    finalLog += `âŒ [${new Date().toISOString()}] Erreur: ${error.message}\n`;

    await supabase
      .from("deployments")
      .update({
        status: "failed",
        build_log: finalLog,
        completed_at: new Date().toISOString(),
      })
      .eq("id", deploymentId);

    // Nettoyer en cas d'erreur
    try {
      await execCommand(
        `rm -rf ${path.join(__dirname, "../../temp", deploymentId)}`
      );
    } catch (cleanupError) {
      console.error("âŒ Erreur nettoyage:", cleanupError);
    }
  }
}

// Fonction de vÃ©rification universelle corrigÃ©e
async function verifyUniversalBuild(deploymentDir, frameworks, buildLog) {
  const distPath = path.join(deploymentDir, "dist");
  const assetsPath = path.join(distPath, "assets");

  try {
    // VÃ©rifier que dist existe
    const distExists = await fs
      .access(distPath)
      .then(() => true)
      .catch(() => false);
    if (!distExists) {
      buildLog += `âŒ Dossier dist/ non trouvÃ©\n`;
      return buildLog;
    }

    // VÃ©rifier les assets
    const assetsExists = await fs
      .access(assetsPath)
      .then(() => true)
      .catch(() => false);
    if (assetsExists) {
      const assets = await fs.readdir(assetsPath);
      const cssFiles = assets.filter((f) => f.endsWith(".css"));
      const jsFiles = assets.filter((f) => f.endsWith(".js"));

      buildLog += `ğŸ“ Assets gÃ©nÃ©rÃ©s: ${cssFiles.length} CSS, ${jsFiles.length} JS\n`;

      // VÃ©rifications spÃ©cifiques par framework
      for (const cssFile of cssFiles) {
        const cssPath = path.join(assetsPath, cssFile);
        const cssContent = await fs.readFile(cssPath, "utf8");
        const cssSize = cssContent.length;

        buildLog += `ğŸ“„ ${cssFile}: ${cssSize} caractÃ¨res\n`;

        // VÃ©rification Tailwind
        if (frameworks.includes("tailwind")) {
          if (cssContent.includes("@tailwind") && cssSize < 10000) {
            buildLog += `âš ï¸ Tailwind non compilÃ© dans ${cssFile}\n`;

            // Tentative de recompilation
            try {
              await execCommand(
                `cd ${deploymentDir} && npx tailwindcss -o dist/assets/${cssFile} --minify`
              );
              const newContent = await fs.readFile(cssPath, "utf8");
              buildLog += `ğŸ”§ Tailwind recompilÃ© (${newContent.length} caractÃ¨res)\n`;
            } catch (e) {
              buildLog += `âŒ Ã‰chec recompilation: ${e.message}\n`;
            }
          } else if (cssSize > 10000) {
            buildLog += `âœ… Tailwind correctement compilÃ©\n`;
          }
        }

        // VÃ©rification AOS
        if (frameworks.includes("aos")) {
          if (
            cssContent.includes(".aos-animate") ||
            cssContent.includes("[data-aos]")
          ) {
            buildLog += `âœ… Styles AOS trouvÃ©s\n`;
          } else {
            buildLog += `âš ï¸ Styles AOS manquants\n`;
          }
        }

        // VÃ©rification Bootstrap/Bulma
        if (
          frameworks.includes("bootstrap") &&
          cssContent.includes(".container")
        ) {
          buildLog += `âœ… Styles Bootstrap trouvÃ©s\n`;
        }
        if (frameworks.includes("bulma") && cssContent.includes(".button")) {
          buildLog += `âœ… Styles Bulma trouvÃ©s\n`;
        }
      }
    } else {
      buildLog += `âš ï¸ Dossier assets/ non trouvÃ©\n`;
    }

    // VÃ©rifier index.html
    const indexPath = path.join(distPath, "index.html");
    const indexExists = await fs
      .access(indexPath)
      .then(() => true)
      .catch(() => false);
    if (indexExists) {
      const indexContent = await fs.readFile(indexPath, "utf8");
      buildLog += `ğŸ“ index.html: ${indexContent.length} caractÃ¨res\n`;

      // VÃ©rifier les liens vers les assets
      const cssLinks = (indexContent.match(/href="[^"]*\.css"/g) || []).length;
      const jsLinks = (indexContent.match(/src="[^"]*\.js"/g) || []).length;

      buildLog += `ğŸ”— Liens CSS: ${cssLinks}, Liens JS: ${jsLinks}\n`;

      // Corriger les chemins si nÃ©cessaire
      if (
        indexContent.includes('href="/assets/') ||
        indexContent.includes('src="/assets/')
      ) {
        const correctedContent = indexContent
          .replace(/href="\/assets\//g, 'href="./assets/')
          .replace(/src="\/assets\//g, 'src="./assets/');

        await fs.writeFile(indexPath, correctedContent);
        buildLog += `ğŸ”§ Chemins absolus corrigÃ©s en relatifs\n`;
      }
    }
  } catch (error) {
    buildLog += `âš ï¸ Erreur vÃ©rification: ${error.message}\n`;
  }

  return buildLog;
}

// Fonction utilitaire pour mettre Ã  jour les logs
async function updateDeploymentLog(deploymentId, buildLog) {
  try {
    await supabase
      .from("deployments")
      .update({ build_log: buildLog })
      .eq("id", deploymentId);
  } catch (error) {
    console.error("âŒ Erreur mise Ã  jour logs:", error);
  }
}

// Fonction utilitaire pour exÃ©cuter des commandes
// function execCommand(command, timeout = 300000) {
//   return new Promise((resolve, reject) => {
//     exec(command, { timeout }, (error, stdout, stderr) => {
//       if (error) {
//         const errorMessage = `Command: ${command}\nError: ${error.message}\nStdout: ${stdout}\nStderr: ${stderr}`;
//         reject(new Error(errorMessage));
//         return;
//       }
//       resolve(stdout);
//     });
//   });
// }
function execCommand(command, envVars = {}, timeout = 300000) {
  return new Promise((resolve, reject) => {
    const options = {
      timeout,
      env: { ...process.env, ...envVars },
    };

    exec(command, options, (error, stdout, stderr) => {
      if (error) {
        const errorMessage = `Command: ${command}\nError: ${error.message}\nStdout: ${stdout}\nStderr: ${stderr}`;
        reject(new Error(errorMessage));
        return;
      }
      resolve(stdout);
    });
  });
}

module.exports = router;
