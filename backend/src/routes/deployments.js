// backend/src/routes/deployments.js - CORRIG√â FINAL
const express = require("express");
const router = express.Router();
const supabase = require("../config/supabase");
const { exec } = require("child_process");
const fs = require("fs").promises;
const path = require("path");
const { requireAuth } = require("../middleware/auth");

// Route pour r√©cup√©rer les d√©ploiements d'un projet
router.get("/projects/:projectId", requireAuth, async (req, res) => {
  try {
    console.log(`üìã R√©cup√©ration d√©ploiements projet ${req.params.projectId}`);

    const { page = 1, limit = 20 } = req.query;

    const { data: deployments, error } = await supabase
      .from("deployments")
      .select("*")
      .eq("project_id", req.params.projectId)
      .order("started_at", { ascending: false })
      .limit(parseInt(limit));

    if (error) {
      console.error("‚ùå Erreur r√©cup√©ration d√©ploiements:", error);
      return res.status(500).json({
        success: false,
        error: "Erreur lors de la r√©cup√©ration des d√©ploiements",
        details: error.message,
      });
    }

    res.json({
      success: true,
      deployments: deployments || [],
    });
  } catch (error) {
    console.error("‚ùå Erreur:", error);
    res.status(500).json({
      success: false,
      error: "Erreur serveur",
    });
  }
});

// Route pour r√©cup√©rer UN d√©ploiement sp√©cifique (manquant dans ton backend)
router.get("/:deploymentId", requireAuth, async (req, res) => {
  try {
    console.log(`üîç R√©cup√©ration d√©ploiement ${req.params.deploymentId}`);

    const { data: deployment, error } = await supabase
      .from("deployments")
      .select("*, projects!inner(user_id, name)")
      .eq("id", req.params.deploymentId)
      .eq("projects.user_id", req.user.id)
      .single();

    if (error || !deployment) {
      return res.status(404).json({
        success: false,
        error: "D√©ploiement non trouv√©",
      });
    }

    res.json({
      success: true,
      deployment,
    });
  } catch (error) {
    console.error("‚ùå Erreur r√©cup√©ration d√©ploiement:", error);
    res.status(500).json({
      success: false,
      error: "Erreur serveur",
    });
  }
});

// Route pour les statistiques des d√©ploiements
router.get("/stats", requireAuth, async (req, res) => {
  try {
    console.log(`üìä R√©cup√©ration stats pour ${req.user.username}`);

    const { data: projects } = await supabase
      .from("projects")
      .select("id")
      .eq("user_id", req.user.id);

    if (!projects || projects.length === 0) {
      return res.json({
        success: true,
        stats: {
          totalDeployments: 0,
          successfulDeployments: 0,
          failedDeployments: 0,
          successRate: 0,
        },
      });
    }

    const projectIds = projects.map((p) => p.id);

    // Compter tous les d√©ploiements
    const { count: totalDeployments } = await supabase
      .from("deployments")
      .select("*", { count: "exact" })
      .in("project_id", projectIds);

    // Compter les d√©ploiements r√©ussis
    const { count: successfulDeployments } = await supabase
      .from("deployments")
      .select("*", { count: "exact" })
      .in("project_id", projectIds)
      .eq("status", "success");

    // Compter les d√©ploiements √©chou√©s
    const { count: failedDeployments } = await supabase
      .from("deployments")
      .select("*", { count: "exact" })
      .in("project_id", projectIds)
      .eq("status", "failed");

    const successRate =
      totalDeployments > 0
        ? Math.round((successfulDeployments / totalDeployments) * 100)
        : 0;

    res.json({
      success: true,
      stats: {
        totalDeployments: totalDeployments || 0,
        successfulDeployments: successfulDeployments || 0,
        failedDeployments: failedDeployments || 0,
        successRate,
      },
    });
  } catch (error) {
    console.error("‚ùå Erreur r√©cup√©ration statistiques:", error);
    res.status(500).json({
      success: false,
      error: "Erreur serveur",
    });
  }
});

// Route pour lancer un d√©ploiement
router.post("/deploy/:projectId", requireAuth, async (req, res) => {
  const projectId = req.params.projectId;
  console.log(
    `üöÄ Lancement d√©ploiement projet ${projectId} par ${req.user.username}`
  );

  try {
    // V√©rifier que le projet appartient √† l'utilisateur
    const { data: project, error: projectError } = await supabase
      .from("projects")
      .select("*")
      .eq("id", projectId)
      .eq("user_id", req.user.id)
      .single();

    if (projectError || !project) {
      return res.status(404).json({
        success: false,
        error: "Projet non trouv√©",
      });
    }

    // V√©rifier qu'il n'y a pas d√©j√† un d√©ploiement en cours
    const { data: pendingDeployment } = await supabase
      .from("deployments")
      .select("id")
      .eq("project_id", projectId)
      .in("status", [
        "pending",
        "building",
        "cloning",
        "deploying",
        "configuring",
      ])
      .limit(1);

    if (pendingDeployment && pendingDeployment.length > 0) {
      return res.status(409).json({
        success: false,
        error: "Un d√©ploiement est d√©j√† en cours pour ce projet",
      });
    }

    // Cr√©er un nouveau d√©ploiement
    const { data: deployment, error: deploymentError } = await supabase
      .from("deployments")
      .insert([
        {
          project_id: projectId,
          status: "pending",
          started_at: new Date().toISOString(),
        },
      ])
      .select()
      .single();

    if (deploymentError) {
      console.error("‚ùå Erreur cr√©ation d√©ploiement:", deploymentError);
      return res.status(500).json({
        success: false,
        error: "Impossible de cr√©er le d√©ploiement",
        details: deploymentError.message,
      });
    }

    // Lancer le processus de d√©ploiement en arri√®re-plan
    deployProject(deployment.id, project);

    res.json({
      success: true,
      deployment: {
        id: deployment.id,
        status: "pending",
        projectId: projectId,
      },
      message: "D√©ploiement lanc√©",
    });
  } catch (error) {
    console.error("‚ùå Erreur lancement d√©ploiement:", error);
    res.status(500).json({
      success: false,
      error: "Erreur lors du lancement du d√©ploiement",
    });
  }
});

// Route pour r√©cup√©rer les logs d'un d√©ploiement
router.get("/:deploymentId/logs", requireAuth, async (req, res) => {
  try {
    const { data: deployment, error } = await supabase
      .from("deployments")
      .select("build_log, deploy_log, status, projects!inner(user_id)")
      .eq("id", req.params.deploymentId)
      .eq("projects.user_id", req.user.id)
      .single();

    if (error || !deployment) {
      return res.status(404).json({
        success: false,
        error: "D√©ploiement non trouv√©",
      });
    }

    res.json({
      success: true,
      logs: {
        build: deployment.build_log || "",
        deploy: deployment.deploy_log || "",
      },
      status: deployment.status,
    });
  } catch (error) {
    console.error("‚ùå Erreur r√©cup√©ration logs:", error);
    res.status(500).json({
      success: false,
      error: "Erreur serveur",
    });
  }
});

// Route pour annuler un d√©ploiement (DELETE au lieu de POST)
router.delete("/:deploymentId", requireAuth, async (req, res) => {
  try {
    console.log(`‚ùå Annulation d√©ploiement ${req.params.deploymentId}`);

    const { data: deployment, error } = await supabase
      .from("deployments")
      .select("*, projects!inner(user_id)")
      .eq("id", req.params.deploymentId)
      .eq("projects.user_id", req.user.id)
      .single();

    if (error || !deployment) {
      return res.status(404).json({
        success: false,
        error: "D√©ploiement non trouv√©",
      });
    }

    if (deployment.status === "success" || deployment.status === "failed") {
      return res.status(400).json({
        success: false,
        error: "D√©ploiement d√©j√† termin√©",
      });
    }

    // Marquer comme annul√©
    await supabase
      .from("deployments")
      .update({
        status: "cancelled",
        completed_at: new Date().toISOString(),
        build_log:
          (deployment.build_log || "") +
          "\n‚ùå D√©ploiement annul√© par l'utilisateur",
      })
      .eq("id", req.params.deploymentId);

    res.json({
      success: true,
      message: "D√©ploiement annul√©",
    });
  } catch (error) {
    console.error("‚ùå Erreur annulation:", error);
    res.status(500).json({
      success: false,
      error: "Erreur serveur",
    });
  }
});

// Fonction pour d√©ployer un projet (processus asynchrone)
// async function deployProject(deploymentId, project) {
//   const deploymentDir = path.join(__dirname, "../../temp", deploymentId);
//   const outputDir = path.join(__dirname, "../../public", project.id);
//   let buildLog = "";

//   try {
//     // Mettre √† jour le statut √† 'cloning'
//     buildLog += `üöÄ [${new Date().toISOString()}] D√©marrage du d√©ploiement...\n`;
//     await supabase
//       .from("deployments")
//       .update({
//         status: "cloning",
//         build_log: buildLog,
//       })
//       .eq("id", deploymentId);

//     // Cr√©er les dossiers n√©cessaires
//     await fs.mkdir(deploymentDir, { recursive: true });
//     await fs.mkdir(outputDir, { recursive: true });

//     // √âtape 1: Cloner le repository
//     buildLog += `üì• [${new Date().toISOString()}] Clonage de ${
//       project.github_repo
//     }...\n`;
//     await updateDeploymentLog(deploymentId, buildLog);

//     try {
//       const cloneCommand = `git clone https://github.com/${project.github_repo}.git ${deploymentDir}`;
//       await execCommand(cloneCommand);
//       buildLog += `‚úÖ Repository clon√© avec succ√®s\n`;
//     } catch (error) {
//       throw new Error(`Erreur lors du clonage: ${error.message}`);
//     }

//     // Changer vers la branche sp√©cifi√©e
//     if (
//       project.branch &&
//       project.branch !== "main" &&
//       project.branch !== "master"
//     ) {
//       buildLog += `üîÑ Basculement vers la branche ${project.branch}...\n`;
//       await updateDeploymentLog(deploymentId, buildLog);

//       try {
//         await execCommand(
//           `cd ${deploymentDir} && git checkout ${project.branch}`
//         );
//         buildLog += `‚úÖ Basculement vers ${project.branch} r√©ussi\n`;
//       } catch (error) {
//         buildLog += `‚ö†Ô∏è Impossible de basculer vers ${project.branch}, utilisation de la branche par d√©faut\n`;
//       }
//     }

//     // R√©cup√©rer le hash du commit
//     let commitHash = "";
//     try {
//       commitHash = await execCommand(
//         `cd ${deploymentDir} && git rev-parse HEAD`
//       );
//       commitHash = commitHash.trim();

//       await supabase
//         .from("deployments")
//         .update({ commit_hash: commitHash })
//         .eq("id", deploymentId);

//       buildLog += `üìã Commit: ${commitHash.substring(0, 8)}\n`;
//     } catch (error) {
//       buildLog += `‚ö†Ô∏è Impossible de r√©cup√©rer le hash du commit\n`;
//     }

//     // √âtape 2: Installation des d√©pendances
//     buildLog += `üì¶ [${new Date().toISOString()}] Installation des d√©pendances...\n`;
//     await supabase
//       .from("deployments")
//       .update({ status: "building", build_log: buildLog })
//       .eq("id", deploymentId);

//     const packageJsonPath = path.join(deploymentDir, "package.json");
//     try {
//       await fs.access(packageJsonPath);

//       // D√©tecter le gestionnaire de paquets
//       const yarnLockExists = await fs
//         .access(path.join(deploymentDir, "yarn.lock"))
//         .then(() => true)
//         .catch(() => false);
//       const pnpmLockExists = await fs
//         .access(path.join(deploymentDir, "pnpm-lock.yaml"))
//         .then(() => true)
//         .catch(() => false);

//       let installCommand = project.install_command || "npm install";
//       if (pnpmLockExists && !project.install_command) {
//         installCommand = "pnpm install";
//       } else if (yarnLockExists && !project.install_command) {
//         installCommand = "yarn install";
//       }

//       buildLog += `üîß Commande d'installation: ${installCommand}\n`;
//       await updateDeploymentLog(deploymentId, buildLog);

//       await execCommand(`cd ${deploymentDir} && ${installCommand}`);
//       buildLog += `‚úÖ D√©pendances install√©es avec succ√®s\n`;
//     } catch (error) {
//       buildLog += `‚ö†Ô∏è Pas de package.json trouv√© ou erreur d'installation\n`;
//     }

//     // √âtape 3: Build du projet
//     if (project.build_command) {
//       buildLog += `üèóÔ∏è [${new Date().toISOString()}] Build du projet...\n`;
//       buildLog += `üîß Commande: ${project.build_command}\n`;
//       await updateDeploymentLog(deploymentId, buildLog);

//       try {
//         await execCommand(`cd ${deploymentDir} && ${project.build_command}`);
//         buildLog += `‚úÖ Build r√©ussi\n`;
//       } catch (buildError) {
//         buildLog += `‚ö†Ô∏è Build √©chou√©: ${buildError.message}\n`;
//         buildLog += `üìÅ D√©ploiement des fichiers source...\n`;
//       }
//     }

//     // √âtape 4: D√©ploiement des fichiers
//     buildLog += `üìÅ [${new Date().toISOString()}] D√©ploiement des fichiers...\n`;
//     await supabase
//       .from("deployments")
//       .update({ status: "deploying", build_log: buildLog })
//       .eq("id", deploymentId);

//     const outputDirectory = project.output_dir || "dist";
//     const sourceDir = path.join(deploymentDir, outputDirectory);

//     try {
//       await fs.access(sourceDir);
//       await execCommand(`cp -r ${sourceDir}/* ${outputDir}/`);
//       buildLog += `‚úÖ Fichiers copi√©s depuis ${outputDirectory}\n`;
//     } catch (error) {
//       try {
//         await execCommand(
//           `find ${deploymentDir} -maxdepth 3 \\( -name "*.html" -o -name "*.css" -o -name "*.js" -o -name "*.png" -o -name "*.jpg" -o -name "*.gif" -o -name "*.svg" \\) -exec cp {} ${outputDir}/ \\;`
//         );
//         buildLog += `‚úÖ Fichiers web copi√©s\n`;
//       } catch (copyError) {
//         throw new Error(
//           `Impossible de copier les fichiers: ${copyError.message}`
//         );
//       }
//     }

//     // √âtape 5: Configuration du domaine
//     buildLog += `üåê [${new Date().toISOString()}] Configuration du domaine...\n`;
//     await supabase
//       .from("deployments")
//       .update({ status: "configuring", build_log: buildLog })
//       .eq("id", deploymentId);

//     let domain = project.domain;
//     if (!domain) {
//       const slug = project.name.toLowerCase().replace(/[^a-z0-9]/g, "-");
//       const shortId = project.id.split("-")[0];
//       domain = `${slug}-${shortId}.localhost:3001`;

//       await supabase
//         .from("projects")
//         .update({
//           domain,
//           status: "active",
//           last_deployed: new Date().toISOString(),
//         })
//         .eq("id", project.id);
//     }

//     buildLog += `‚úÖ [${new Date().toISOString()}] D√©ploiement r√©ussi!\n`;
//     buildLog += `üåê Site disponible sur: http://${domain}\n`;

//     // Marquer comme r√©ussi
//     await supabase
//       .from("deployments")
//       .update({
//         status: "success",
//         build_log: buildLog,
//         completed_at: new Date().toISOString(),
//       })
//       .eq("id", deploymentId);

//     // Nettoyer apr√®s d√©lai
//     setTimeout(async () => {
//       try {
//         await execCommand(`rm -rf ${deploymentDir}`);
//       } catch (error) {
//         console.error("‚ùå Erreur nettoyage:", error);
//       }
//     }, 10000);
//   } catch (error) {
//     console.error("‚ùå Erreur d√©ploiement:", error);
//     buildLog += `‚ùå [${new Date().toISOString()}] Erreur: ${error.message}\n`;

//     await supabase
//       .from("deployments")
//       .update({
//         status: "failed",
//         build_log: buildLog,
//         completed_at: new Date().toISOString(),
//       })
//       .eq("id", deploymentId);

//     // Nettoyer m√™me en cas d'erreur
//     try {
//       await execCommand(`rm -rf ${deploymentDir}`);
//     } catch (cleanupError) {
//       console.error("‚ùå Erreur nettoyage:", cleanupError);
//     }
//   }
// }
// backend/src/routes/deployments.js - FONCTION deployProject CORRIG√âE

// azo lazaina mety
// async function deployProject(deploymentId, project) {
//   try {
//     console.log(
//       `üöÄ D√©marrage d√©ploiement ${deploymentId} pour ${project.name}`
//     );

//     // NE PAS utiliser BuildService.deployProject qui cr√©e un autre d√©ploiement
//     // Faire le build directement ici

//     const deploymentDir = path.join(__dirname, "../../temp", deploymentId);
//     const outputDir = path.join(__dirname, "../../public", project.id); // Utiliser project.id pas project.name
//     let buildLog = "";

//     // Mettre √† jour le statut
//     buildLog += `üöÄ [${new Date().toISOString()}] D√©marrage du d√©ploiement...\n`;
//     await supabase
//       .from("deployments")
//       .update({
//         status: "cloning",
//         build_log: buildLog,
//       })
//       .eq("id", deploymentId);

//     // Cr√©er les dossiers
//     await fs.mkdir(deploymentDir, { recursive: true });
//     await fs.mkdir(outputDir, { recursive: true });

//     // R√©cup√©rer le token GitHub
//     const { data: user } = await supabase
//       .from("users")
//       .select("access_token")
//       .eq("id", project.user_id)
//       .single();

//     if (!user?.access_token) {
//       throw new Error("Token GitHub manquant pour l'utilisateur");
//     }

//     // Cloner avec le token
//     buildLog += `üì• [${new Date().toISOString()}] Clonage de ${
//       project.github_repo
//     }...\n`;
//     await updateDeploymentLog(deploymentId, buildLog);

//     const cloneCommand = `git clone --depth 1 -b ${
//       project.branch || "main"
//     } https://${user.access_token}@github.com/${
//       project.github_repo
//     }.git ${deploymentDir}`;
//     await execCommand(cloneCommand);
//     buildLog += `‚úÖ Repository clon√© avec succ√®s\n`;

//     // R√©cup√©rer le commit hash
//     try {
//       const commitHash = await execCommand(
//         `cd ${deploymentDir} && git rev-parse HEAD`
//       );
//       await supabase
//         .from("deployments")
//         .update({ commit_hash: commitHash.trim() })
//         .eq("id", deploymentId);
//       buildLog += `üìã Commit: ${commitHash.trim().substring(0, 8)}\n`;
//     } catch (error) {
//       buildLog += `‚ö†Ô∏è Impossible de r√©cup√©rer le commit hash\n`;
//     }

//     // Installation des d√©pendances
//     await supabase
//       .from("deployments")
//       .update({ status: "building", build_log: buildLog })
//       .eq("id", deploymentId);

//     const packageJsonPath = path.join(deploymentDir, "package.json");
//     try {
//       await fs.access(packageJsonPath);

//       buildLog += `üì¶ [${new Date().toISOString()}] Installation des d√©pendances...\n`;
//       await updateDeploymentLog(deploymentId, buildLog);

//       const installCmd = project.install_command || "npm install";
//       buildLog += `üîß Commande: ${installCmd}\n`;

//       await execCommand(`cd ${deploymentDir} && ${installCmd}`);
//       buildLog += `‚úÖ D√©pendances install√©es\n`;
//     } catch (error) {
//       buildLog += `‚ö†Ô∏è Pas de package.json ou erreur installation\n`;
//     }

//     // Build du projet
//     if (project.build_command) {
//       buildLog += `üèóÔ∏è [${new Date().toISOString()}] Build du projet...\n`;
//       buildLog += `üîß Commande: ${project.build_command}\n`;
//       await updateDeploymentLog(deploymentId, buildLog);

//       try {
//         await execCommand(`cd ${deploymentDir} && ${project.build_command}`);
//         buildLog += `‚úÖ Build r√©ussi\n`;
//       } catch (buildError) {
//         buildLog += `‚ö†Ô∏è Build √©chou√©, copie des fichiers source\n`;
//       }
//     }

//     // Copie des fichiers
//     await supabase
//       .from("deployments")
//       .update({ status: "deploying", build_log: buildLog })
//       .eq("id", deploymentId);

//     buildLog += `üìÅ [${new Date().toISOString()}] Copie des fichiers...\n`;
//     await updateDeploymentLog(deploymentId, buildLog);

//     const outputDirectory = project.output_dir || "dist";
//     const sourceDir = path.join(deploymentDir, outputDirectory);

//     try {
//       await fs.access(sourceDir);
//       await execCommand(`cp -r ${sourceDir}/* ${outputDir}/`);
//       buildLog += `‚úÖ Fichiers copi√©s depuis ${outputDirectory}\n`;
//     } catch (error) {
//       // Copier les fichiers HTML/CSS/JS
//       try {
//         await execCommand(
//           `find ${deploymentDir} -maxdepth 2 \\( -name "*.html" -o -name "*.css" -o -name "*.js" -o -name "*.png" -o -name "*.jpg" -o -name "*.gif" -o -name "*.svg" \\) -exec cp {} ${outputDir}/ \\; 2>/dev/null || true`
//         );
//         await execCommand(
//           `rsync -av --include="*/" --include="*.html" --include="*.css" --include="*.js" --include="*.jsx" --include="*.tsx" --include="*.png" --include="*.jpg" --include="*.svg" --include="*.ico" --include="*.gif" --include="*.woff*" --include="*.ttf" --exclude="*" "${deploymentDir}/" "${outputDir}/"`
//         );
//         buildLog += `‚úÖ Fichiers statiques copi√©s\n`;
//       } catch (copyError) {
//         await execCommand(
//           `find ${deploymentDir} -maxdepth 2 \\( -name "*.html" -o -name "*.css" -o -name "*.js" -o -name "*.png" -o -name "*.jpg" -o -name "*.gif" -o -name "*.svg" \\) -exec cp {} ${outputDir}/ \\; 2>/dev/null || true`
//         );
//         buildLog += `‚ö†Ô∏è Erreur copie fichiers: ${copyError.message}\n`;
//       }
//     }

//     // Lister les fichiers copi√©s pour debug
//     try {
//       const fileList = await execCommand(`ls -la "${outputDir}"`);
//       buildLog += `üìã Contenu du dossier de d√©ploiement:\n${fileList}`;
//     } catch (listError) {
//       buildLog += `‚ö†Ô∏è Impossible de lister les fichiers copi√©s\n`;
//     }

//     // Configuration domaine
//     await supabase
//       .from("deployments")
//       .update({ status: "configuring", build_log: buildLog })
//       .eq("id", deploymentId);

//     const domain = `${project.name
//       .toLowerCase()
//       .replace(/[^a-z0-9]/g, "-")}.madahost.me`;

//     await supabase
//       .from("projects")
//       .update({
//         domain,
//         status: "active",
//         last_deployed: new Date().toISOString(),
//       })
//       .eq("id", project.id);

//     buildLog += `‚úÖ [${new Date().toISOString()}] D√©ploiement r√©ussi!\n`;
//     buildLog += `üåê Site disponible: http://localhost:3002/project/${project.id}/\n`;

//     // Succ√®s final
//     await supabase
//       .from("deployments")
//       .update({
//         status: "success",
//         build_log: buildLog,
//         completed_at: new Date().toISOString(),
//       })
//       .eq("id", deploymentId);

//     // Nettoyer apr√®s 10 secondes
//     setTimeout(async () => {
//       try {
//         await execCommand(`rm -rf ${deploymentDir}`);
//         console.log(`üßπ Nettoyage termin√©: ${deploymentDir}`);
//       } catch (error) {
//         console.error("‚ùå Erreur nettoyage:", error);
//       }
//     }, 10000);
//   } catch (error) {
//     console.error(`‚ùå Erreur d√©ploiement ${deploymentId}:`, error);

//     await supabase
//       .from("deployments")
//       .update({
//         status: "failed",
//         build_log: `‚ùå [${new Date().toISOString()}] Erreur: ${
//           error.message
//         }\n`,
//         completed_at: new Date().toISOString(),
//       })
//       .eq("id", deploymentId);

//     // Nettoyer en cas d'erreur
//     try {
//       await execCommand(
//         `rm -rf ${path.join(__dirname, "../../temp", deploymentId)}`
//       );
//     } catch (cleanupError) {
//       console.error("‚ùå Erreur nettoyage:", cleanupError);
//     }
//   }
// }

// backend/src/routes/deployments.js - Fonction deployProject CORRIG√âE pour copier tous les assets

async function deployProject(deploymentId, project) {
  try {
    console.log(
      `üöÄ D√©marrage d√©ploiement ${deploymentId} pour ${project.name}`
    );

    const deploymentDir = path.join(__dirname, "../../temp", deploymentId);
    const outputDir = path.join(__dirname, "../../public", project.id);
    let buildLog = "";

    // Mettre √† jour le statut
    buildLog += `üöÄ [${new Date().toISOString()}] D√©marrage du d√©ploiement...\n`;
    await supabase
      .from("deployments")
      .update({
        status: "cloning",
        build_log: buildLog,
      })
      .eq("id", deploymentId);

    // Cr√©er les dossiers
    await fs.mkdir(deploymentDir, { recursive: true });
    await fs.mkdir(outputDir, { recursive: true });

    // R√©cup√©rer le token GitHub
    const { data: user } = await supabase
      .from("users")
      .select("access_token")
      .eq("id", project.user_id)
      .single();

    if (!user?.access_token) {
      throw new Error("Token GitHub manquant pour l'utilisateur");
    }

    // Cloner avec le token
    buildLog += `üì• [${new Date().toISOString()}] Clonage de ${
      project.github_repo
    }...\n`;
    await updateDeploymentLog(deploymentId, buildLog);

    const cloneCommand = `git clone --depth 1 -b ${
      project.branch || "main"
    } https://${user.access_token}@github.com/${
      project.github_repo
    }.git ${deploymentDir}`;
    await execCommand(cloneCommand);
    buildLog += `‚úÖ Repository clon√© avec succ√®s\n`;

    // R√©cup√©rer le commit hash
    try {
      const commitHash = await execCommand(
        `cd ${deploymentDir} && git rev-parse HEAD`
      );
      await supabase
        .from("deployments")
        .update({ commit_hash: commitHash.trim() })
        .eq("id", deploymentId);
      buildLog += `üìã Commit: ${commitHash.trim().substring(0, 8)}\n`;
    } catch (error) {
      buildLog += `‚ö†Ô∏è Impossible de r√©cup√©rer le commit hash\n`;
    }

    // Installation des d√©pendances
    await supabase
      .from("deployments")
      .update({ status: "building", build_log: buildLog })
      .eq("id", deploymentId);

    const packageJsonPath = path.join(deploymentDir, "package.json");
    try {
      await fs.access(packageJsonPath);

      buildLog += `üì¶ [${new Date().toISOString()}] Installation des d√©pendances...\n`;
      await updateDeploymentLog(deploymentId, buildLog);

      const installCmd = project.install_command || "npm install";
      buildLog += `üîß Commande: ${installCmd}\n`;

      await execCommand(`cd ${deploymentDir} && ${installCmd}`);
      buildLog += `‚úÖ D√©pendances install√©es\n`;
    } catch (error) {
      buildLog += `‚ö†Ô∏è Pas de package.json ou erreur installation\n`;
    }

    // Build du projet
    // if (project.build_command) {
    //   buildLog += `üèóÔ∏è [${new Date().toISOString()}] Build du projet...\n`;
    //   buildLog += `üîß Commande: ${project.build_command}\n`;
    //   await updateDeploymentLog(deploymentId, buildLog);

    //   try {
    //     await execCommand(`cd ${deploymentDir} && ${project.build_command}`);
    //     buildLog += `‚úÖ Build r√©ussi\n`;
    //   } catch (buildError) {
    //     buildLog += `‚ö†Ô∏è Build √©chou√©, copie des fichiers source\n`;
    //   }
    // }
    if (project.build_command) {
      buildLog += `üèóÔ∏è [${new Date().toISOString()}] Build du projet...\n`;
      buildLog += `üîß Commande: ${project.build_command}\n`;
      await updateDeploymentLog(deploymentId, buildLog);

      try {
        // Pour Vite, assurer que les assets ont les bons chemins relatifs
        const viteConfigPath = path.join(deploymentDir, "vite.config.js");
        const packageJsonPath = path.join(deploymentDir, "package.json");

        // V√©rifier si c'est un projet Vite
        let isViteProject = false;
        try {
          const packageJson = JSON.parse(
            await fs.readFile(packageJsonPath, "utf8")
          );
          isViteProject =
            packageJson.devDependencies?.vite || packageJson.dependencies?.vite;
          buildLog += `üîç Projet Vite d√©tect√©: ${!!isViteProject}\n`;
        } catch (e) {
          buildLog += `‚ö†Ô∏è Impossible de lire package.json\n`;
        }

        // Si c'est Vite, cr√©er/modifier la config pour les chemins relatifs
        if (isViteProject) {
          const viteConfig = `import { defineConfig } from 'vite'
            import react from '@vitejs/plugin-react'

            export default defineConfig({
              plugins: [react()],
              base: './',  // CRUCIAL: chemins relatifs pour les assets
              build: {
                outDir: 'dist',
                assetsDir: 'assets'
              }
            })`;
          await fs.writeFile(viteConfigPath, viteConfig);
          buildLog += `‚öôÔ∏è Configuration Vite mise √† jour pour chemins relatifs\n`;
        }

        await execCommand(`cd ${deploymentDir} && ${project.build_command}`);
        buildLog += `‚úÖ Build r√©ussi\n`;
      } catch (buildError) {
        buildLog += `‚ö†Ô∏è Build √©chou√©: ${buildError.message}\n`;
        buildLog += `üìÅ Tentative de d√©ploiement des fichiers source...\n`;
      }
    }

    // Copie des fichiers - CORRECTION ICI
    await supabase
      .from("deployments")
      .update({ status: "deploying", build_log: buildLog })
      .eq("id", deploymentId);

    buildLog += `üìÅ [${new Date().toISOString()}] Copie des fichiers...\n`;
    await updateDeploymentLog(deploymentId, buildLog);

    const outputDirectory = project.output_dir || "dist";
    const sourceDir = path.join(deploymentDir, outputDirectory);

    // Debug: v√©rifier l'existence du dossier
    buildLog += `üîç V√©rification dossier source: ${sourceDir}\n`;

    try {
      // Lister le contenu du dossier de d√©ploiement pour debug
      const tempContent = await execCommand(`ls -la "${deploymentDir}"`);
      buildLog += `üìã Contenu dossier temp:\n${tempContent}`;

      // V√©rifier si le dossier de build existe
      await fs.access(sourceDir);
      buildLog += `‚úÖ Dossier ${outputDirectory} trouv√©\n`;

      // Lister le contenu du dossier dist pour debug
      const distContent = await execCommand(`ls -la "${sourceDir}"`);
      buildLog += `üìÅ Contenu du dossier ${outputDirectory}:\n${distContent}`;

      // CORRECTION: Nettoyer et recr√©er le dossier de destination
      await execCommand(`rm -rf "${outputDir}"/*`);
      await execCommand(`mkdir -p "${outputDir}"`);

      // Copier TOUT le contenu en pr√©servant la structure
      await execCommand(`cp -r "${sourceDir}/"* "${outputDir}/"`);
      buildLog += `‚úÖ Tous les fichiers copi√©s depuis ${outputDirectory} avec structure pr√©serv√©e\n`;

      // V√©rifier la structure finale copi√©e
      const finalStructure = await execCommand(`find "${outputDir}" -type f`);
      buildLog += `üìä Structure finale:\n${finalStructure}`;

      // V√©rifier sp√©cifiquement le dossier assets
      try {
        const assetsContent = await execCommand(
          `ls -la "${outputDir}/assets/"`
        );
        buildLog += `üìÅ Contenu du dossier assets:\n${assetsContent}`;
      } catch (assetsError) {
        buildLog += `‚ö†Ô∏è Pas de dossier assets dans la destination finale\n`;
      }
    } catch (error) {
      buildLog += `‚ö†Ô∏è Dossier ${outputDirectory} introuvable, tentative copie alternative...\n`;

      try {
        // Alternative: Copier r√©cursivement tous les fichiers statiques
        await execCommand(
          `rsync -av --include="*/" --include="*.html" --include="*.css" --include="*.js" --include="*.png" --include="*.jpg" --include="*.svg" --include="*.ico" --include="*.gif" --include="*.woff*" --include="*.ttf" --exclude="*" "${deploymentDir}/" "${outputDir}/"`
        );
        buildLog += `‚úÖ Fichiers statiques copi√©s avec rsync\n`;
      } catch (rsyncError) {
        // Derni√®re tentative: copie basique
        await execCommand(
          `find "${deploymentDir}" -maxdepth 3 \\( -name "*.html" -o -name "*.css" -o -name "*.js" -o -name "*.png" -o -name "*.jpg" -o -name "*.gif" -o -name "*.svg" -o -name "*.ico" -o -name "*.woff*" -o -name "*.ttf" \\) -exec cp {} "${outputDir}/" \\; 2>/dev/null || true`
        );
        buildLog += `‚úÖ Fichiers statiques copi√©s (m√©thode basique)\n`;
      }
    }
    const indexPath = path.join(outputDir, "index.html");
    try {
      let indexContent = await fs.readFile(indexPath, "utf8");

      buildLog += `üîß [${new Date().toISOString()}] Correction des chemins dans index.html...\n`;

      // Remplacer les chemins absolus par des chemins relatifs
      indexContent = indexContent
        .replace(/href="\/assets\//g, 'href="./assets/')
        .replace(/src="\/assets\//g, 'src="./assets/')
        .replace(/href="\//g, 'href="./')
        .replace(/src="\//g, 'src="./');

      await fs.writeFile(indexPath, indexContent);
      buildLog += `‚úÖ Chemins corrig√©s dans index.html\n`;

      // V√©rifier que les fichiers CSS/JS r√©f√©renc√©s existent
      const cssMatches =
        indexContent.match(/href="\.\/assets\/[^"]+\.css"/g) || [];
      const jsMatches =
        indexContent.match(/src="\.\/assets\/[^"]+\.js"/g) || [];

      buildLog += `üé® Fichiers CSS r√©f√©renc√©s: ${cssMatches.length}\n`;
      buildLog += `üìú Fichiers JS r√©f√©renc√©s: ${jsMatches.length}\n`;

      // V√©rifier l'existence des fichiers CSS
      for (const cssMatch of cssMatches) {
        const cssFile = cssMatch.match(/href="(.+)"/)[1].replace("./", "");
        const cssPath = path.join(outputDir, cssFile);
        try {
          await fs.access(cssPath);
          buildLog += `‚úÖ CSS trouv√©: ${cssFile}\n`;
        } catch (e) {
          buildLog += `‚ùå CSS manquant: ${cssFile}\n`;
        }
      }
    } catch (indexFixError) {
      buildLog += `‚ö†Ô∏è Impossible de corriger index.html: ${indexFixError.message}\n`;
    }

    // Lister la structure finale pour debug
    try {
      const structure = await execCommand(
        `find "${outputDir}" -type f | head -20`
      );
      buildLog += `üìä Structure finale (20 premiers fichiers):\n${structure}`;
    } catch (listError) {
      buildLog += `‚ö†Ô∏è Impossible de lister la structure finale\n`;
    }
    // Lister les fichiers copi√©s pour debug
    try {
      const fileList = await execCommand(`ls -la "${outputDir}"`);
      buildLog += `üìã Contenu du dossier de d√©ploiement:\n${fileList}`;
    } catch (listError) {
      buildLog += `‚ö†Ô∏è Impossible de lister les fichiers copi√©s\n`;
    }

    // Configuration domaine
    await supabase
      .from("deployments")
      .update({ status: "configuring", build_log: buildLog })
      .eq("id", deploymentId);

    const domain = `${project.name
      .toLowerCase()
      .replace(/[^a-z0-9]/g, "-")}.madahost.me`;

    await supabase
      .from("projects")
      .update({
        domain,
        status: "active",
        last_deployed: new Date().toISOString(),
      })
      .eq("id", project.id);

    buildLog += `‚úÖ [${new Date().toISOString()}] D√©ploiement r√©ussi!\n`;
    buildLog += `üåê Site disponible: http://localhost:3002/project/${project.id}/\n`;

    // Succ√®s final
    await supabase
      .from("deployments")
      .update({
        status: "success",
        build_log: buildLog,
        completed_at: new Date().toISOString(),
      })
      .eq("id", deploymentId);

    // Nettoyer apr√®s 10 secondes
    setTimeout(async () => {
      try {
        await execCommand(`rm -rf ${deploymentDir}`);
        console.log(`üßπ Nettoyage termin√©: ${deploymentDir}`);
      } catch (error) {
        console.error("‚ùå Erreur nettoyage:", error);
      }
    }, 10000);
  } catch (error) {
    console.error(`‚ùå Erreur d√©ploiement ${deploymentId}:`, error);

    await supabase
      .from("deployments")
      .update({
        status: "failed",
        build_log: `‚ùå [${new Date().toISOString()}] Erreur: ${
          error.message
        }\n`,
        completed_at: new Date().toISOString(),
      })
      .eq("id", deploymentId);

    // Nettoyer en cas d'erreur
    try {
      await execCommand(
        `rm -rf ${path.join(__dirname, "../../temp", deploymentId)}`
      );
    } catch (cleanupError) {
      console.error("‚ùå Erreur nettoyage:", cleanupError);
    }
  }
}

// Fonction utilitaire pour mettre √† jour les logs
async function updateDeploymentLog(deploymentId, buildLog) {
  try {
    await supabase
      .from("deployments")
      .update({ build_log: buildLog })
      .eq("id", deploymentId);
  } catch (error) {
    console.error("‚ùå Erreur mise √† jour logs:", error);
  }
}

// Fonction utilitaire pour ex√©cuter des commandes
function execCommand(command, timeout = 300000) {
  return new Promise((resolve, reject) => {
    exec(command, { timeout }, (error, stdout, stderr) => {
      if (error) {
        const errorMessage = `Command: ${command}\nError: ${error.message}\nStdout: ${stdout}\nStderr: ${stderr}`;
        reject(new Error(errorMessage));
        return;
      }
      resolve(stdout);
    });
  });
}

module.exports = router;
