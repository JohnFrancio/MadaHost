// backend/src/routes/deployments.js - CORRIGÃ‰ FINAL
const express = require("express");
const UniversalFrameworkHandler = require("../utils/universalFrameworkHandler");
const router = express.Router();
const supabase = require("../config/supabase");
const { exec } = require("child_process");
const fs = require("fs").promises;
const path = require("path");
const { requireAuth } = require("../middleware/auth");

// Route pour rÃ©cupÃ©rer les dÃ©ploiements d'un projet
router.get("/projects/:projectId", requireAuth, async (req, res) => {
  try {
    console.log(`ðŸ“‹ RÃ©cupÃ©ration dÃ©ploiements projet ${req.params.projectId}`);

    const { page = 1, limit = 20 } = req.query;

    const { data: deployments, error } = await supabase
      .from("deployments")
      .select("*")
      .eq("project_id", req.params.projectId)
      .order("started_at", { ascending: false })
      .limit(parseInt(limit));

    if (error) {
      console.error("âŒ Erreur rÃ©cupÃ©ration dÃ©ploiements:", error);
      return res.status(500).json({
        success: false,
        error: "Erreur lors de la rÃ©cupÃ©ration des dÃ©ploiements",
        details: error.message,
      });
    }

    res.json({
      success: true,
      deployments: deployments || [],
    });
  } catch (error) {
    console.error("âŒ Erreur:", error);
    res.status(500).json({
      success: false,
      error: "Erreur serveur",
    });
  }
});

// Route pour rÃ©cupÃ©rer UN dÃ©ploiement spÃ©cifique (manquant dans ton backend)
router.get("/:deploymentId", requireAuth, async (req, res) => {
  try {
    console.log(`ðŸ” RÃ©cupÃ©ration dÃ©ploiement ${req.params.deploymentId}`);

    const { data: deployment, error } = await supabase
      .from("deployments")
      .select("*, projects!inner(user_id, name)")
      .eq("id", req.params.deploymentId)
      .eq("projects.user_id", req.user.id)
      .single();

    if (error || !deployment) {
      return res.status(404).json({
        success: false,
        error: "DÃ©ploiement non trouvÃ©",
      });
    }

    res.json({
      success: true,
      deployment,
    });
  } catch (error) {
    console.error("âŒ Erreur rÃ©cupÃ©ration dÃ©ploiement:", error);
    res.status(500).json({
      success: false,
      error: "Erreur serveur",
    });
  }
});

// Route pour les statistiques des dÃ©ploiements
router.get("/stats", requireAuth, async (req, res) => {
  try {
    console.log(`ðŸ“Š RÃ©cupÃ©ration stats pour ${req.user.username}`);

    const { data: projects } = await supabase
      .from("projects")
      .select("id")
      .eq("user_id", req.user.id);

    if (!projects || projects.length === 0) {
      return res.json({
        success: true,
        stats: {
          totalDeployments: 0,
          successfulDeployments: 0,
          failedDeployments: 0,
          successRate: 0,
        },
      });
    }

    const projectIds = projects.map((p) => p.id);

    // Compter tous les dÃ©ploiements
    const { count: totalDeployments } = await supabase
      .from("deployments")
      .select("*", { count: "exact" })
      .in("project_id", projectIds);

    // Compter les dÃ©ploiements rÃ©ussis
    const { count: successfulDeployments } = await supabase
      .from("deployments")
      .select("*", { count: "exact" })
      .in("project_id", projectIds)
      .eq("status", "success");

    // Compter les dÃ©ploiements Ã©chouÃ©s
    const { count: failedDeployments } = await supabase
      .from("deployments")
      .select("*", { count: "exact" })
      .in("project_id", projectIds)
      .eq("status", "failed");

    const successRate =
      totalDeployments > 0
        ? Math.round((successfulDeployments / totalDeployments) * 100)
        : 0;

    res.json({
      success: true,
      stats: {
        totalDeployments: totalDeployments || 0,
        successfulDeployments: successfulDeployments || 0,
        failedDeployments: failedDeployments || 0,
        successRate,
      },
    });
  } catch (error) {
    console.error("âŒ Erreur rÃ©cupÃ©ration statistiques:", error);
    res.status(500).json({
      success: false,
      error: "Erreur serveur",
    });
  }
});

// Route pour lancer un dÃ©ploiement
router.post("/deploy/:projectId", requireAuth, async (req, res) => {
  const projectId = req.params.projectId;
  console.log(
    `ðŸš€ Lancement dÃ©ploiement projet ${projectId} par ${req.user.username}`
  );

  try {
    // VÃ©rifier que le projet appartient Ã  l'utilisateur
    const { data: project, error: projectError } = await supabase
      .from("projects")
      .select("*")
      .eq("id", projectId)
      .eq("user_id", req.user.id)
      .single();

    if (projectError || !project) {
      return res.status(404).json({
        success: false,
        error: "Projet non trouvÃ©",
      });
    }

    // VÃ©rifier qu'il n'y a pas dÃ©jÃ  un dÃ©ploiement en cours
    const { data: pendingDeployment } = await supabase
      .from("deployments")
      .select("id")
      .eq("project_id", projectId)
      .in("status", [
        "pending",
        "building",
        "cloning",
        "deploying",
        "configuring",
      ])
      .limit(1);

    if (pendingDeployment && pendingDeployment.length > 0) {
      return res.status(409).json({
        success: false,
        error: "Un dÃ©ploiement est dÃ©jÃ  en cours pour ce projet",
      });
    }

    // CrÃ©er un nouveau dÃ©ploiement
    const { data: deployment, error: deploymentError } = await supabase
      .from("deployments")
      .insert([
        {
          project_id: projectId,
          status: "pending",
          started_at: new Date().toISOString(),
        },
      ])
      .select()
      .single();

    if (deploymentError) {
      console.error("âŒ Erreur crÃ©ation dÃ©ploiement:", deploymentError);
      return res.status(500).json({
        success: false,
        error: "Impossible de crÃ©er le dÃ©ploiement",
        details: deploymentError.message,
      });
    }

    // Lancer le processus de dÃ©ploiement en arriÃ¨re-plan
    deployProject(deployment.id, project);

    res.json({
      success: true,
      deployment: {
        id: deployment.id,
        status: "pending",
        projectId: projectId,
      },
      message: "DÃ©ploiement lancÃ©",
    });
  } catch (error) {
    console.error("âŒ Erreur lancement dÃ©ploiement:", error);
    res.status(500).json({
      success: false,
      error: "Erreur lors du lancement du dÃ©ploiement",
    });
  }
});

// Route pour rÃ©cupÃ©rer les logs d'un dÃ©ploiement
router.get("/:deploymentId/logs", requireAuth, async (req, res) => {
  try {
    const { data: deployment, error } = await supabase
      .from("deployments")
      .select("build_log, deploy_log, status, projects!inner(user_id)")
      .eq("id", req.params.deploymentId)
      .eq("projects.user_id", req.user.id)
      .single();

    if (error || !deployment) {
      return res.status(404).json({
        success: false,
        error: "DÃ©ploiement non trouvÃ©",
      });
    }

    res.json({
      success: true,
      logs: {
        build: deployment.build_log || "",
        deploy: deployment.deploy_log || "",
      },
      status: deployment.status,
    });
  } catch (error) {
    console.error("âŒ Erreur rÃ©cupÃ©ration logs:", error);
    res.status(500).json({
      success: false,
      error: "Erreur serveur",
    });
  }
});

// Route pour annuler un dÃ©ploiement (DELETE au lieu de POST)
router.delete("/:deploymentId", requireAuth, async (req, res) => {
  try {
    console.log(`âŒ Annulation dÃ©ploiement ${req.params.deploymentId}`);

    const { data: deployment, error } = await supabase
      .from("deployments")
      .select("*, projects!inner(user_id)")
      .eq("id", req.params.deploymentId)
      .eq("projects.user_id", req.user.id)
      .single();

    if (error || !deployment) {
      return res.status(404).json({
        success: false,
        error: "DÃ©ploiement non trouvÃ©",
      });
    }

    if (deployment.status === "success" || deployment.status === "failed") {
      return res.status(400).json({
        success: false,
        error: "DÃ©ploiement dÃ©jÃ  terminÃ©",
      });
    }

    // Marquer comme annulÃ©
    await supabase
      .from("deployments")
      .update({
        status: "cancelled",
        completed_at: new Date().toISOString(),
        build_log:
          (deployment.build_log || "") +
          "\nâŒ DÃ©ploiement annulÃ© par l'utilisateur",
      })
      .eq("id", req.params.deploymentId);

    res.json({
      success: true,
      message: "DÃ©ploiement annulÃ©",
    });
  } catch (error) {
    console.error("âŒ Erreur annulation:", error);
    res.status(500).json({
      success: false,
      error: "Erreur serveur",
    });
  }
});

async function deployProject(deploymentId, project) {
  try {
    console.log(
      `ðŸš€ DÃ©marrage dÃ©ploiement ${deploymentId} pour ${project.name}`
    );

    const deploymentDir = path.join(__dirname, "../../temp", deploymentId);
    const outputDir = path.join(__dirname, "../../public", project.id);
    let buildLog = "";

    // Mettre Ã  jour le statut
    buildLog += `ðŸš€ [${new Date().toISOString()}] DÃ©marrage du dÃ©ploiement...\n`;
    await supabase
      .from("deployments")
      .update({
        status: "cloning",
        build_log: buildLog,
      })
      .eq("id", deploymentId);

    // CrÃ©er les dossiers
    await fs.mkdir(deploymentDir, { recursive: true });
    await fs.mkdir(outputDir, { recursive: true });

    // RÃ©cupÃ©rer le token GitHub
    const { data: user } = await supabase
      .from("users")
      .select("access_token")
      .eq("id", project.user_id)
      .single();

    if (!user?.access_token) {
      throw new Error("Token GitHub manquant pour l'utilisateur");
    }

    // Cloner avec le token
    buildLog += `ðŸ“¥ [${new Date().toISOString()}] Clonage de ${
      project.github_repo
    }...\n`;
    await updateDeploymentLog(deploymentId, buildLog);

    const cloneCommand = `git clone --depth 1 -b ${
      project.branch || "main"
    } https://${user.access_token}@github.com/${
      project.github_repo
    }.git ${deploymentDir}`;
    await execCommand(cloneCommand);
    buildLog += `âœ… Repository clonÃ© avec succÃ¨s\n`;

    // RÃ©cupÃ©rer le commit hash
    try {
      const commitHash = await execCommand(
        `cd ${deploymentDir} && git rev-parse HEAD`
      );
      await supabase
        .from("deployments")
        .update({ commit_hash: commitHash.trim() })
        .eq("id", deploymentId);
      buildLog += `ðŸ“‹ Commit: ${commitHash.trim().substring(0, 8)}\n`;
    } catch (error) {
      buildLog += `âš ï¸ Impossible de rÃ©cupÃ©rer le commit hash\n`;
    }

    // ==================== DÃ‰TECTION ET INSTALLATION AUTOMATIQUE ====================

    buildLog += `ðŸ” [${new Date().toISOString()}] DÃ©tection des frameworks et dÃ©pendances...\n`;
    await updateDeploymentLog(deploymentId, buildLog);

    const frameworkHandler = new UniversalFrameworkHandler();
    const { frameworks, log: detectionLog } =
      await frameworkHandler.detectFrameworks(deploymentDir);
    buildLog += detectionLog;

    if (frameworks.length === 0) {
      buildLog += `â„¹ï¸ Aucun framework CSS/JS spÃ©cial dÃ©tectÃ©\n`;
    } else {
      buildLog += `ðŸŽ¯ Frameworks dÃ©tectÃ©s: ${frameworks.join(", ")}\n`;
    }

    // Configuration et installation des dÃ©pendances manquantes
    const { buildLog: setupLog, missingDeps } =
      await frameworkHandler.setupFrameworks(
        deploymentDir,
        frameworks,
        buildLog
      );
    buildLog = setupLog;

    // ==================== FIN DÃ‰TECTION ====================

    // Installation des dÃ©pendances (avec les nouvelles dÃ©pendances)
    await supabase
      .from("deployments")
      .update({ status: "building", build_log: buildLog })
      .eq("id", deploymentId);

    const packageJsonPath = path.join(deploymentDir, "package.json");
    try {
      await fs.access(packageJsonPath);

      buildLog += `ðŸ“¦ [${new Date().toISOString()}] Installation des dÃ©pendances...\n`;
      if (missingDeps.length > 0) {
        buildLog += `ðŸ”§ Nouvelles dÃ©pendances: ${missingDeps.join(", ")}\n`;
      }
      await updateDeploymentLog(deploymentId, buildLog);

      const installCmd = project.install_command || "npm install";
      buildLog += `ðŸ”§ Commande: ${installCmd}\n`;

      await execCommand(`cd ${deploymentDir} && ${installCmd}`);
      buildLog += `âœ… DÃ©pendances installÃ©es\n`;
    } catch (error) {
      buildLog += `âš ï¸ Pas de package.json ou erreur installation\n`;
    }

    // Build du projet
    if (project.build_command) {
      buildLog += `ðŸ—ï¸ [${new Date().toISOString()}] Build du projet...\n`;
      buildLog += `ðŸ”§ Commande: ${project.build_command}\n`;
      await updateDeploymentLog(deploymentId, buildLog);

      try {
        // Variables d'environnement optimisÃ©es
        const buildEnv = {
          NODE_ENV: "production",
          TAILWIND_MODE: frameworks.includes("tailwind") ? "build" : undefined,
          VITE_NODE_ENV: "production",
          CI: "true",
        };

        await execCommand(
          `cd ${deploymentDir} && ${project.build_command}`,
          buildEnv
        );
        buildLog += `âœ… Build rÃ©ussi\n`;
      } catch (buildError) {
        buildLog += `âš ï¸ Build Ã©chouÃ©: ${buildError.message}\n`;

        // Tentative de build sans minification en cas d'erreur terser
        if (buildError.message.includes("terser")) {
          buildLog += `ðŸ”„ Tentative build sans minification...\n`;
          try {
            // Modifier temporairement vite.config.js pour dÃ©sactiver terser
            const viteConfigPath = path.join(deploymentDir, "vite.config.js");
            const noMinifyConfig = `import { defineConfig } from 'vite'
              import react from '@vitejs/plugin-react'

              export default defineConfig({
                plugins: [react()],
                base: './',
                build: {
                  minify: false,  // DÃ©sactiver la minification
                  outDir: 'dist',
                  assetsDir: 'assets'
                }
              })`;
            await fs.writeFile(viteConfigPath, noMinifyConfig);

            await execCommand(
              `cd ${deploymentDir} && ${project.build_command}`
            );
            buildLog += `âœ… Build rÃ©ussi sans minification\n`;
          } catch (e) {
            buildLog += `âŒ Ã‰chec build alternatif: ${e.message}\n`;
            throw buildError; // Rethrow l'erreur originale
          }
        } else {
          throw buildError;
        }
      }
    }

    // Copie des fichiers - logique existante amÃ©liorÃ©e
    await supabase
      .from("deployments")
      .update({ status: "deploying", build_log: buildLog })
      .eq("id", deploymentId);

    buildLog += `ðŸ“ [${new Date().toISOString()}] Copie des fichiers...\n`;
    await updateDeploymentLog(deploymentId, buildLog);

    const outputDirectory = project.output_dir || "dist";
    const sourceDir = path.join(deploymentDir, outputDirectory);

    buildLog += `ðŸ” VÃ©rification dossier source: ${sourceDir}\n`;

    try {
      await fs.access(sourceDir);
      buildLog += `âœ… Dossier ${outputDirectory} trouvÃ©\n`;

      // Debug: lister le contenu du dossier source
      const sourceContent = await execCommand(`ls -la "${sourceDir}"`);
      buildLog += `ðŸ“ Contenu source:\n${sourceContent}`;

      // Nettoyer et recrÃ©er le dossier de destination
      await execCommand(`rm -rf "${outputDir}"/*`);
      await execCommand(`mkdir -p "${outputDir}"`);

      // Copier avec preservation des liens symboliques et permissions
      await execCommand(
        `cp -r "${sourceDir}/"* "${outputDir}/" 2>/dev/null || true`
      );
      buildLog += `âœ… Fichiers copiÃ©s depuis ${outputDirectory}\n`;

      // VÃ©rifier que les assets ont Ã©tÃ© copiÃ©s
      const assetsDir = path.join(outputDir, "assets");
      if (
        await fs
          .access(assetsDir)
          .then(() => true)
          .catch(() => false)
      ) {
        const assetsContent = await execCommand(`ls -la "${assetsDir}"`);
        buildLog += `ðŸ“ Assets copiÃ©s:\n${assetsContent}`;
      }
    } catch (error) {
      buildLog += `âš ï¸ Dossier ${outputDirectory} introuvable, copie alternative...\n`;

      try {
        // Alternative avec rsync
        await execCommand(
          `rsync -av --include="*/" --include="*.html" --include="*.css" --include="*.js" --include="*.png" --include="*.jpg" --include="*.svg" --include="*.ico" --include="*.gif" --include="*.woff*" --include="*.ttf" --exclude="*" "${deploymentDir}/" "${outputDir}/"`
        );
        buildLog += `âœ… Fichiers statiques copiÃ©s avec rsync\n`;
      } catch (rsyncError) {
        // DerniÃ¨re tentative avec find
        await execCommand(
          `find "${deploymentDir}" -maxdepth 3 \\( -name "*.html" -o -name "*.css" -o -name "*.js" -o -name "*.png" -o -name "*.jpg" -o -name "*.gif" -o -name "*.svg" -o -name "*.ico" -o -name "*.woff*" -o -name "*.ttf" \\) -exec cp {} "${outputDir}/" \\; 2>/dev/null || true`
        );
        buildLog += `âœ… Fichiers statiques copiÃ©s (mÃ©thode basique)\n`;
      }
    }

    // Correction des chemins dans index.html
    const indexPath = path.join(outputDir, "index.html");
    try {
      let indexContent = await fs.readFile(indexPath, "utf8");

      buildLog += `ðŸ”§ [${new Date().toISOString()}] Correction des chemins dans index.html...\n`;

      // Remplacer les chemins absolus par des chemins relatifs
      const originalContent = indexContent;
      indexContent = indexContent
        .replace(/href="\/assets\//g, 'href="./assets/')
        .replace(/src="\/assets\//g, 'src="./assets/')
        .replace(/href="\//g, 'href="./')
        .replace(/src="\//g, 'src="./');

      if (originalContent !== indexContent) {
        await fs.writeFile(indexPath, indexContent);
        buildLog += `âœ… Chemins corrigÃ©s dans index.html\n`;
      } else {
        buildLog += `â„¹ï¸ Chemins dÃ©jÃ  corrects dans index.html\n`;
      }

      // VÃ©rifier les rÃ©fÃ©rences CSS/JS
      const cssMatches = indexContent.match(/href="[^"]*\.css"/g) || [];
      const jsMatches = indexContent.match(/src="[^"]*\.js"/g) || [];

      buildLog += `ðŸŽ¨ RÃ©fÃ©rences CSS: ${cssMatches.length}, JS: ${jsMatches.length}\n`;
    } catch (indexFixError) {
      buildLog += `âš ï¸ Impossible de corriger index.html: ${indexFixError.message}\n`;
    }

    // Configuration domaine
    await supabase
      .from("deployments")
      .update({ status: "configuring", build_log: buildLog })
      .eq("id", deploymentId);

    const domain = `${project.name
      .toLowerCase()
      .replace(/[^a-z0-9]/g, "-")}.madahost.me`;

    await supabase
      .from("projects")
      .update({
        domain,
        status: "active",
        last_deployed: new Date().toISOString(),
      })
      .eq("id", project.id);

    // VÃ©rification finale
    try {
      const finalStructure = await execCommand(
        `find "${outputDir}" -type f | head -10`
      );
      buildLog += `ðŸ“Š Structure finale (10 premiers fichiers):\n${finalStructure}`;
    } catch (e) {
      buildLog += `âš ï¸ Impossible de lister la structure finale\n`;
    }

    buildLog += `âœ… [${new Date().toISOString()}] DÃ©ploiement rÃ©ussi!\n`;
    buildLog += `ðŸŒ Site disponible: http://localhost:3002/project/${project.id}/\n`;

    // SuccÃ¨s final
    await supabase
      .from("deployments")
      .update({
        status: "success",
        build_log: buildLog,
        completed_at: new Date().toISOString(),
      })
      .eq("id", deploymentId);

    // Nettoyer aprÃ¨s 10 secondes
    setTimeout(async () => {
      try {
        await execCommand(`rm -rf ${deploymentDir}`);
        console.log(`ðŸ§¹ Nettoyage terminÃ©: ${deploymentDir}`);
      } catch (error) {
        console.error("âŒ Erreur nettoyage:", error);
      }
    }, 10000);
  } catch (error) {
    console.error(`âŒ Erreur dÃ©ploiement ${deploymentId}:`, error);

    let finalLog = buildLog || "";
    finalLog += `âŒ [${new Date().toISOString()}] Erreur: ${error.message}\n`;

    await supabase
      .from("deployments")
      .update({
        status: "failed",
        build_log: finalLog,
        completed_at: new Date().toISOString(),
      })
      .eq("id", deploymentId);

    // Nettoyer en cas d'erreur
    try {
      await execCommand(
        `rm -rf ${path.join(__dirname, "../../temp", deploymentId)}`
      );
    } catch (cleanupError) {
      console.error("âŒ Erreur nettoyage:", cleanupError);
    }
  }
}

// Fonction utilitaire pour mettre Ã  jour les logs
async function updateDeploymentLog(deploymentId, buildLog) {
  try {
    await supabase
      .from("deployments")
      .update({ build_log: buildLog })
      .eq("id", deploymentId);
  } catch (error) {
    console.error("âŒ Erreur mise Ã  jour logs:", error);
  }
}

function execCommand(command, envVars = {}, timeout = 300000) {
  return new Promise((resolve, reject) => {
    const options = {
      timeout,
      env: { ...process.env, ...envVars },
    };

    exec(command, options, (error, stdout, stderr) => {
      if (error) {
        const errorMessage = `Command: ${command}\nError: ${error.message}\nStdout: ${stdout}\nStderr: ${stderr}`;
        reject(new Error(errorMessage));
        return;
      }
      resolve(stdout);
    });
  });
}

module.exports = router;
